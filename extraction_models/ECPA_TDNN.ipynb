{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hldx3uJgdsJY"
      },
      "source": [
        "## **Install SpeechBrain Libraries **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5Cx65NbaoYL",
        "outputId": "4bdeb426-59f4-4884-fea8-c6d59cbdc66b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting speechbrain\n",
            "  Downloading speechbrain-1.0.2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (2.32.3)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2025.1.31)\n",
            "Downloading speechbrain-1.0.2-py3-none-any.whl (824 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, hyperpyyaml, speechbrain\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed hyperpyyaml-1.2.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 speechbrain-1.0.2\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install speechbrain\n",
        "!pip install torchaudio\n",
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "e3028a782a9d41f1aad459f0e6587958",
            "31991c1728c440a893559dd3e9387f43",
            "f8823c0ee70e466eaf602cedb27d535f",
            "d5458d36d843457a85e700eaaa8f3030",
            "970c848a97794953bbc8e6ca735b0541",
            "edfc6502b13440fbae2065f6753b2a08",
            "349c3c1e02244c7a9e068e2508bae487",
            "69f46c0262ef44adba0473dc5ecf94c9",
            "e743b9ca126c4778a96c3aa4b41d9271",
            "cef1d887fe1d4fe6b65b558d7407dc0e",
            "c3569d50de084ab2af3f65ed195f8207",
            "e734005da43a40f3b0482eaba963d330",
            "28930f69fd864f179706f68a3976cd8a",
            "d3cd0b86f8a945bfb43582f5789cae15",
            "531e98f676854aefb9491758e9d0597e",
            "ccd026315c064d7aaba3ec1ce3e88b63",
            "d3144ed8a0ac484fa715ecc16390c5cf",
            "a584764b7262466b9eff1dfb551c000f",
            "18f8de743b3f43faac5843b7591bf1ee",
            "bd4b14fe103544668a43e19e6bd7b296",
            "245074d8d0a946e680aa8f85ad8d1273",
            "c4d578aa11af437ea3267e131b657471",
            "866deff0bb9c4af9a60c5bc8e21f4e4a",
            "ed5a69752d5d40f9b53ae52952584848",
            "eea72e95808443f3a3528b99ce3627a9",
            "4419feb94bcd427b90c394c15bfe8c75",
            "d4e79c19046a46878933ba21068aefad",
            "5f63022e5feb4471b1960d50771b5ad7",
            "d1e667d3954e487a8bb24a70cb13bb6d",
            "d9ea661213434369b3813ad59967ae2a",
            "0e946b6d3148470a87cafe2def2e89dc",
            "d99e2b8c8a004626bb02505a0632efd8",
            "ed7a43e7dd5846e4964a0e5aa477d1a6",
            "2d3e9bfaf611453f8208f34f79cc14f5",
            "aa665cd63f464689a0ddebb0eaf84bde",
            "0fb4208a8c084612b8f81f2a045630de",
            "515bd341696140ee9e94dcbff887f522",
            "fb0c37acd8c14c7fa8d6e223cfd5cbd2",
            "2d96f876062543798f2d6abdb079dc27",
            "bafe0c1dd1a94f3bbe1e3f6da087b9cb",
            "979d99fd4c9a47b79d6992e6064b758d",
            "3f6532a9d47145989b9b7241635f466b",
            "ce970b007bd246579e06ae586ec0f71c",
            "e72d16ca8c344cf8b9db34338534e8e5",
            "01fa7478093a42c88871cbc0f2aa72b1",
            "2c7e929de5e04185bb5d111b668fe65b",
            "d04038695b704a3ab3189e84f096cce8",
            "50015659624e4c4d9c8d98ae3d4f02c2",
            "09483848d84141d486e1ea70181d4228",
            "083b5de742a441a9a49ddf850cbeb06f",
            "e09c82ffc71b45fcb830e35c725f8f2e",
            "f57d7e83f0b24bd5bb9cdb98b86bac81",
            "7ca3f81f49e0448e9b27c6d535f54525",
            "3526b09ba70b4c22a1b3def7138e04be",
            "bd29d1e9912e4eabb9129401f99c1206"
          ]
        },
        "id": "GqQ_5BkTeX5Y",
        "outputId": "ee69ec59-f0e5-4dcd-c180-7f2312c8d0ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-bfb60a4e9a65>:3: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
            "  from speechbrain.pretrained import EncoderClassifier\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3028a782a9d41f1aad459f0e6587958",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "hyperparams.yaml:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e734005da43a40f3b0482eaba963d330",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "embedding_model.ckpt:   0%|          | 0.00/83.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "866deff0bb9c4af9a60c5bc8e21f4e4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "mean_var_norm_emb.ckpt:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d3e9bfaf611453f8208f34f79cc14f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "classifier.ckpt:   0%|          | 0.00/5.53M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01fa7478093a42c88871cbc0f2aa72b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "label_encoder.txt:   0%|          | 0.00/129k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  stats = torch.load(path, map_location=device)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "# Load the pre-trained ECAPA-TDNN model\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D91-dF37esdx"
      },
      "source": [
        "# ** Load and Preprocess Audio Data**:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bq3mHjztbBj",
        "outputId": "a0f34b5c-241f-49b8-adbe-db2e01d7f61f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NDWZFTZejtH",
        "outputId": "76590a4b-9761-4e65-9e93-935e7ae70a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 343 enroll files, 960 trial_m files, and 1018 trial_f files.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define paths to the folders in the shared folder\n",
        "enroll_folder = \"/content/drive/MyDrive/ML_project/libri_dev_enrolls_B3/wav\"\n",
        "trial_m_folder = \"/content/drive/MyDrive/ML_project/libri_dev_trials_m_B3/wav\"\n",
        "trial_f_folder = \"/content/drive/MyDrive/ML_project/libri_dev_trials_f_B3/wav\"\n",
        "\n",
        "# List all .wav files in each folder\n",
        "enroll_files = [os.path.join(enroll_folder, f) for f in os.listdir(enroll_folder) if f.endswith('.wav')]\n",
        "trial_m_files = [os.path.join(trial_m_folder, f) for f in os.listdir(trial_m_folder) if f.endswith('.wav')]\n",
        "trial_f_files = [os.path.join(trial_f_folder, f) for f in os.listdir(trial_f_folder) if f.endswith('.wav')]\n",
        "\n",
        "print(f\"Found {len(enroll_files)} enroll files, {len(trial_m_files)} trial_m files, and {len(trial_f_files)} trial_f files.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade numba llvmlite\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlCv-kxU2C8x",
        "outputId": "f5ecfa72-0fd8-4d4a-b44a-621f55e6ed4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (0.61.0)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.11/dist-packages (0.44.0)\n",
            "Requirement already satisfied: numpy<2.2,>=1.24 in /usr/local/lib/python3.11/dist-packages (from numba) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bFL3aWDzpJxQ",
        "outputId": "fb7ba1c2-7e68-48b0-abec-269457363218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechbrain\n",
            "  Downloading speechbrain-1.0.2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (2.32.3)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2025.1.31)\n",
            "Downloading speechbrain-1.0.2-py3-none-any.whl (824 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, hyperpyyaml, speechbrain\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 455, in run\n",
            "    installed = install_given_reqs(\n",
            "                ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/__init__.py\", line 70, in install_given_reqs\n",
            "    requirement.install(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_install.py\", line 851, in install\n",
            "    install_wheel(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/install/wheel.py\", line 726, in install_wheel\n",
            "    _install_wheel(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/install/wheel.py\", line 584, in _install_wheel\n",
            "    file.save()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/install/wheel.py\", line 382, in save\n",
            "    shutil.copyfileobj(f, dest)\n",
            "  File \"/usr/lib/python3.11/shutil.py\", line 197, in copyfileobj\n",
            "    buf = fsrc_read(length)\n",
            "          ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/zipfile.py\", line 966, in read\n",
            "    data = self._read1(n)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/zipfile.py\", line 1056, in _read1\n",
            "    self._update_crc(data)\n",
            "  File \"/usr/lib/python3.11/zipfile.py\", line 981, in _update_crc\n",
            "    self._running_crc = crc32(newdata, self._running_crc)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
            "    with self:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/console.py\", line 865, in __exit__\n",
            "    self._exit_buffer()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/console.py\", line 823, in _exit_buffer\n",
            "    self._check_buffer()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/rich/console.py\", line 2060, in _check_buffer\n",
            "    self.file.write(text)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->torchaudio)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (10.3.5.147)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->torchaudio)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'speechbrain'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5b3410fcb23f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speechbrain'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install speechbrain\n",
        "!pip install torchaudio\n",
        "!pip install librosa\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the pre-trained ECAPA-TDNN model\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        ")\n",
        "\n",
        "# Define the load_audio function\n",
        "def load_audio(file_path):\n",
        "    # Load audio file using librosa\n",
        "    audio, sr = librosa.load(file_path, sr=16000)  # Resample to 16kHz if necessary\n",
        "    return audio\n",
        "\n",
        "# Define the preprocess_audio function\n",
        "def preprocess_audio(audio):\n",
        "    # Convert audio to tensor\n",
        "    audio_tensor = torch.tensor(audio).unsqueeze(0)\n",
        "    return audio_tensor\n",
        "\n",
        "# Define the extract_embedding function\n",
        "def extract_embedding(audio_tensor):\n",
        "    with torch.no_grad():\n",
        "        embeddings = classifier.encode_batch(audio_tensor)\n",
        "    return embeddings\n",
        "\n",
        "# Define paths to the folders in the shared folder\n",
        "enroll_folder = \"/content/drive/MyDrive/ML_project/libri_dev_enrolls_B3/wav\"\n",
        "trial_m_folder = \"/content/drive/MyDrive/ML_project/libri_dev_trials_m_B3/wav\"\n",
        "trial_f_folder = \"/content/drive/MyDrive/ML_project/libri_dev_trials_f_B3/wav\"\n",
        "\n",
        "# List all .wav files in each folder\n",
        "enroll_files = [os.path.join(enroll_folder, f) for f in os.listdir(enroll_folder) if f.endswith('.wav')]\n",
        "trial_m_files = [os.path.join(trial_m_folder, f) for f in os.listdir(trial_m_folder) if f.endswith('.wav')]\n",
        "trial_f_files = [os.path.join(trial_f_folder, f) for f in os.listdir(trial_f_folder) if f.endswith('.wav')]\n",
        "\n",
        "print(f\"Found {len(enroll_files)} enroll files, {len(trial_m_files)} trial_m files, and {len(trial_f_files)} trial_f files.\")\n",
        "\n",
        "# Function to process a list of files and save embeddings\n",
        "def process_files(file_list, output_folder):\n",
        "    embeddings = {}\n",
        "    for file_path in file_list:\n",
        "        # Load and preprocess audio\n",
        "        audio = load_audio(file_path)\n",
        "        audio_tensor = preprocess_audio(audio)\n",
        "\n",
        "        # Extract embedding\n",
        "        embedding = extract_embedding(audio_tensor)\n",
        "        embedding = embedding.squeeze().numpy()\n",
        "\n",
        "        # Save embedding with the same filename as the audio file\n",
        "        file_name = os.path.basename(file_path).replace('.wav', '.npy')\n",
        "        output_path = os.path.join(output_folder, file_name)\n",
        "        np.save(output_path, embedding)\n",
        "\n",
        "        # Store embedding in dictionary (optional)\n",
        "        embeddings[file_name] = embedding\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Create output folders for embeddings\n",
        "os.makedirs(\"/content/drive/MyDrive/ML_project/enroll_embeddings\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/ML_project/trial_m_embeddings\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/ML_project/trial_f_embeddings\", exist_ok=True)\n",
        "\n",
        "# Process all files\n",
        "enroll_embeddings = process_files(enroll_files, \"/content/drive/MyDrive/ML_project/enroll_embeddings\")\n",
        "trial_m_embeddings = process_files(trial_m_files, \"/content/drive/MyDrive/ML_project/trial_m_embeddings\")\n",
        "trial_f_embeddings = process_files(trial_f_files, \"/content/drive/MyDrive/ML_project/trial_f_embeddings\")\n",
        "\n",
        "print(\"Embeddings extracted and saved successfully!\")\n",
        "\n",
        "# Verify the output\n",
        "print(\"Enroll Embeddings:\", os.listdir(\"/content/drive/MyDrive/ML_project/enroll_embeddings\"))\n",
        "print(\"Trial M Embeddings:\", os.listdir(\"/content/drive/MyDrive/ML_project/trial_m_embeddings\"))\n",
        "print(\"Trial F Embeddings:\", os.listdir(\"/content/drive/MyDrive/ML_project/trial_f_embeddings\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MuZrbi1QnsL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN0Ejbk752Zh",
        "outputId": "02a7a32c-6953-4632-f51e-712effb6ce96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Type: <class 'numpy.ndarray'>\n",
            "Shape: (192,)\n",
            "Data Type of Elements: float32\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the .npy file\n",
        "data = np.load(\"/content/drive/MyDrive/ML_project/trial_m_embeddings/8297-275156-0013.npy\")\n",
        "\n",
        "# Print basic info\n",
        "print(f\"Data Type: {type(data)}\")\n",
        "print(f\"Shape: {data.shape}\")  # Rows x Columns (if 2D)\n",
        "print(f\"Data Type of Elements: {data.dtype}\")  # Type of stored elements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf6O6dnIWjSi"
      },
      "source": [
        "# FOR TEST EMBEDDINGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snv02EtvWy8n",
        "outputId": "1690dd31-d9a0-44bc-9b54-78c581b1492b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (2.32.3)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain) (0.18.10)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2025.1.31)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  stats = torch.load(path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 438 enroll files, 762 trial_m files, and 734 trial_f files.\n",
            "Embeddings extracted and saved successfully!\n"
          ]
        }
      ],
      "source": [
        "!pip install speechbrain\n",
        "!pip install torchaudio\n",
        "!pip install librosa\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the pre-trained ECAPA-TDNN model\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        ")\n",
        "\n",
        "# Define the load_audio function\n",
        "def load_audio(file_path):\n",
        "    # Load audio file using librosa\n",
        "    audio, sr = librosa.load(file_path, sr=16000)  # Resample to 16kHz if necessary\n",
        "    return audio\n",
        "\n",
        "# Define the preprocess_audio function\n",
        "def preprocess_audio(audio):\n",
        "    # Convert audio to tensor\n",
        "    audio_tensor = torch.tensor(audio).unsqueeze(0)\n",
        "    return audio_tensor\n",
        "\n",
        "# Define the extract_embedding function\n",
        "def extract_embedding(audio_tensor):\n",
        "    with torch.no_grad():\n",
        "        embeddings = classifier.encode_batch(audio_tensor)\n",
        "    return embeddings\n",
        "\n",
        "# Define paths to the folders in the shared folder\n",
        "enroll_folder = \"/content/drive/MyDrive/ML_project/libri_test_enrolls_B3/wav\"\n",
        "trial_m_folder = \"/content/drive/MyDrive/ML_project/libri_test_trials_m_B3/wav\"\n",
        "trial_f_folder = \"/content/drive/MyDrive/ML_project/libri_test_trials_f_B3/wav\"\n",
        "\n",
        "# List all .wav files in each folder\n",
        "enroll_files = [os.path.join(enroll_folder, f) for f in os.listdir(enroll_folder) if f.endswith('.wav')]\n",
        "trial_m_files = [os.path.join(trial_m_folder, f) for f in os.listdir(trial_m_folder) if f.endswith('.wav')]\n",
        "trial_f_files = [os.path.join(trial_f_folder, f) for f in os.listdir(trial_f_folder) if f.endswith('.wav')]\n",
        "\n",
        "print(f\"Found {len(enroll_files)} enroll files, {len(trial_m_files)} trial_m files, and {len(trial_f_files)} trial_f files.\")\n",
        "\n",
        "# Function to process a list of files and save embeddings\n",
        "def process_files(file_list, output_folder):\n",
        "    embeddings = {}\n",
        "    for file_path in file_list:\n",
        "        # Load and preprocess audio\n",
        "        audio = load_audio(file_path)\n",
        "        audio_tensor = preprocess_audio(audio)\n",
        "\n",
        "        # Extract embedding\n",
        "        embedding = extract_embedding(audio_tensor)\n",
        "        embedding = embedding.squeeze().numpy()\n",
        "\n",
        "        # Save embedding with the same filename as the audio file\n",
        "        file_name = os.path.basename(file_path).replace('.wav', '.npy')\n",
        "        output_path = os.path.join(output_folder, file_name)\n",
        "        np.save(output_path, embedding)\n",
        "\n",
        "        # Store embedding in dictionary (optional)\n",
        "        embeddings[file_name] = embedding\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Create output folders for embeddings\n",
        "os.makedirs(\"/content/drive/MyDrive/ML_project/test_enroll_embeddings\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/ML_project/test_trial_m_embeddings\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/ML_project/test_trial_f_embeddings\", exist_ok=True)\n",
        "\n",
        "# Process all files\n",
        "enroll_embeddings = process_files(enroll_files, \"/content/drive/MyDrive/ML_project/test_enroll_embeddings\")\n",
        "trial_m_embeddings = process_files(trial_m_files, \"/content/drive/MyDrive/ML_project/test_trial_m_embeddings\")\n",
        "trial_f_embeddings = process_files(trial_f_files, \"/content/drive/MyDrive/ML_project/test_trial_f_embeddings\")\n",
        "\n",
        "print(\"Embeddings extracted and saved successfully!\")\n",
        "\n",
        "# # Verify the output\n",
        "# print(\"Enroll Embeddings:\", os.listdir(\"/content/drive/MyDrive/ML_project/enroll_embeddings\"))\n",
        "# print(\"Trial M Embeddings:\", os.listdir(\"/content/drive/MyDrive/ML_project/trial_m_embeddings\"))\n",
        "# print(\"Trial F Embeddings:\", os.listdir(\"/content/drive/MyDrive/ML_project/trial_f_embeddings\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRETRAINED MODEL"
      ],
      "metadata": {
        "id": "-ILln9N1nwio"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pe9VYuGym_sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import speechbrain as sb; sb.utils.parameter_transfer.Pretrainer.collect_files('/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/pretrained_models/ECAPA-TDNN_B3')\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JZlpk6yjc84",
        "outputId": "2321f504-b1b2-42d3-ae74-ff7f6344df1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/speechbrain/utils/parameter_transfer.py\", line 224, in collect_files\n",
            "    if self.collect_in is not None:\n",
            "       ^^^^^^^^^^^^^^^\n",
            "AttributeError: 'str' object has no attribute 'collect_in'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dMfmGsVNoOi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOUNT GDRIVE"
      ],
      "metadata": {
        "id": "DHCJwfD28aki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!umount -l /content/drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh9sns7sfqdr",
        "outputId": "02d1b952-13ab-4033-de32-f7218a2e247a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define source and destination paths\n",
        "src_model = \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/pretrained_models/ECAPA-TDNN_B3/embedding_model.ckpt\"\n",
        "dst_model = \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/pretrain_path/embedding_model.ckpt\"\n",
        "\n",
        "# Ensure the destination folder exists\n",
        "os.makedirs(os.path.dirname(dst_model), exist_ok=True)\n",
        "\n",
        "# Copy the model file instead of symlinking\n",
        "shutil.copy(src_model, dst_model)\n",
        "\n",
        "print(\"✅ Model file copied successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "eEHQDSFZpCm1",
        "outputId": "40c1ecfd-4e0e-41e9-ae63-73cd3ab34ed2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/pretrained_models/ECAPA-TDNN_B3/embedding_model.ckpt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-454ba20c9a6b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Copy the model file instead of symlinking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Model file copied successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/pretrained_models/ECAPA-TDNN_B3/embedding_model.ckpt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W8YGAYQXgqEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install dos2unix -y\n",
        "!pip install kaldiio\n",
        "!pip install speechbrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uH1JmOHu44Au",
        "outputId": "bbe73bae-98da-4d3b-9a87-8283dfd76df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "^C\n",
            "Requirement already satisfied: kaldiio in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from kaldiio) (1.26.4)\n",
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (2.32.3)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain) (0.18.10)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/00_extract_emb_fbank.sh\"\n",
        "print(\"File exists:\", os.path.exists(path))\n",
        "print(\"Is a file:\", os.path.isfile(path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4ANPwEi5bpa",
        "outputId": "54eb6f07-9857-4b74-b86b-b9c7877002c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists: True\n",
            "Is a file: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure correct permissions\n",
        "!chmod +x /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/00_extract_emb_fbank.sh\n",
        "\n",
        "# Convert script to UNIX format (if needed)\n",
        "!dos2unix /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/00_extract_emb_fbank.sh\n",
        "\n",
        "# Run the script using bash\n",
        "!bash /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/00_extract_emb_fbank.sh\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wglPGZtGkhkk",
        "outputId": "0dc5c1f1-0be0-432f-8715-35b1b81c550d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dos2unix: converting file /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/00_extract_emb_fbank.sh to Unix format...\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Extract emb for 1272-128104-0011\n",
            "Extract emb for 3752-4943-0017\n",
            "Extract emb for 1272-128104-0005\n",
            "Extract emb for 1272-128104-0010\n",
            "Extract emb for 6313-66125-0002\n",
            "Extract emb for 2803-154320-0007\n",
            "Extract emb for 84-121123-0001\n",
            "Extract emb for 3752-4943-0003\n",
            "Extract emb for 2412-153947-0011\n",
            "Extract emb for 84-121123-0003\n",
            "Extract emb for 2428-83699-0040\n",
            "Extract emb for 3536-23268-0009\n",
            "Extract emb for 2803-154320-0013\n",
            "Extract emb for 7976-105575-0026\n",
            "Extract emb for 6295-244435-0004\n",
            "Extract emb for 2428-83699-0042\n",
            "Extract emb for 2412-153947-0007\n",
            "Extract emb for 7976-105575-0018\n",
            "Extract emb for 84-121123-0015\n",
            "Extract emb for 2803-154320-0011\n",
            "Extract emb for 2803-154320-0005\n",
            "Extract emb for 1462-170138-0026\n",
            "Extract emb for 3752-4943-0015\n",
            "Extract emb for 3752-4943-0001\n",
            "Extract emb for 1272-128104-0006\n",
            "Extract emb for 6313-66125-0014\n",
            "Extract emb for 1272-128104-0013\n",
            "Extract emb for 2803-154320-0004\n",
            "Extract emb for 3752-4943-0000\n",
            "Extract emb for 1272-128104-0007\n",
            "Extract emb for 1673-143396-0009\n",
            "Extract emb for 6313-66125-0000\n",
            "Extract emb for 1462-170138-0027\n",
            "Extract emb for 2412-153947-0012\n",
            "Extract emb for 1993-147149-0010\n",
            "Extract emb for 2803-154320-0010\n",
            "Extract emb for 2412-153947-0006\n",
            "Extract emb for 2902-9006-0004\n",
            "Extract emb for 6295-244435-0017\n",
            "Extract emb for 84-121123-0004\n",
            "Extract emb for 84-121123-0014\n",
            "Extract emb for 7976-105575-0009\n",
            "Extract emb for 7976-105575-0021\n",
            "Extract emb for 6345-64257-0012\n",
            "Extract emb for 84-121123-0000\n",
            "Extract emb for 6295-244435-0003\n",
            "Extract emb for 6345-64257-0016\n",
            "Extract emb for 2035-147960-0009\n",
            "Extract emb for 3752-4943-0004\n",
            "Extract emb for 3536-23268-0026\n",
            "Extract emb for 1993-147149-0028\n",
            "Extract emb for 2412-153947-0016\n",
            "Extract emb for 2803-154320-0014\n",
            "Extract emb for 2803-154320-0000\n",
            "Extract emb for 6345-64257-0003\n",
            "Extract emb for 2803-154320-0001\n",
            "Extract emb for 1272-128104-0002\n",
            "Extract emb for 7976-105575-0020\n",
            "Extract emb for 1272-128104-0003\n",
            "Extract emb for 1462-170138-0022\n",
            "Extract emb for 1993-147149-0001\n",
            "Extract emb for 3752-4943-0005\n",
            "Extract emb for 6313-66125-0004\n",
            "Extract emb for 1993-147149-0014\n",
            "Extract emb for 1462-170138-0023\n",
            "Extract emb for 2412-153947-0002\n",
            "Extract emb for 3752-4943-0010\n",
            "Extract emb for 1993-147149-0000\n",
            "Extract emb for 7976-105575-0008\n",
            "Extract emb for 6345-64257-0017\n",
            "Extract emb for 6295-244435-0016\n",
            "Extract emb for 3536-23268-0027\n",
            "Extract emb for 84-121123-0007\n",
            "Extract emb for 84-121123-0013\n",
            "Extract emb for 84-121123-0005\n",
            "Extract emb for 7976-105575-0022\n",
            "Extract emb for 5895-34615-0008\n",
            "Extract emb for 5536-43358-0008\n",
            "Extract emb for 5895-34615-0020\n",
            "Extract emb for 1272-128104-0014\n",
            "Extract emb for 652-129742-0018\n",
            "Extract emb for 2412-153947-0015\n",
            "Extract emb for 1993-147149-0003\n",
            "Extract emb for 3752-4943-0013\n",
            "Extract emb for 3752-4943-0012\n",
            "Extract emb for 2412-153947-0001\n",
            "Extract emb for 1272-128104-0000\n",
            "Extract emb for 6313-66125-0006\n",
            "Extract emb for 6313-66125-0007\n",
            "Extract emb for 6313-66125-0012\n",
            "Extract emb for 2412-153947-0014\n",
            "Extract emb for 2412-153947-0000\n",
            "Extract emb for 652-129742-0019\n",
            "Extract emb for 84-121123-0006\n",
            "Extract emb for 7976-105575-0023\n",
            "Extract emb for 5895-34615-0009\n",
            "Extract emb for 2803-154320-0002\n",
            "Extract emb for 3536-23268-0018\n",
            "Extract emb for 6345-64257-0014\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Extract emb for 1462-170142-0016\n",
            "Extract emb for 1462-170142-0018\n",
            "Extract emb for 1462-170142-0022\n",
            "Extract emb for 1462-170142-0020\n",
            "Extract emb for 1462-170142-0023\n",
            "Extract emb for 1462-170142-0015\n",
            "Extract emb for 1462-170142-0026\n",
            "Extract emb for 1462-170142-0030\n",
            "Extract emb for 1462-170142-0027\n",
            "Extract emb for 1462-170142-0029\n",
            "Extract emb for 1462-170142-0031\n",
            "Extract emb for 1462-170142-0025\n",
            "Extract emb for 1462-170142-0034\n",
            "Extract emb for 1462-170142-0033\n",
            "Extract emb for 1462-170142-0032\n",
            "Extract emb for 1462-170142-0024\n",
            "Extract emb for 1462-170142-0028\n",
            "Extract emb for 1462-170142-0041\n",
            "Extract emb for 1462-170142-0040\n",
            "Extract emb for 1462-170142-0039\n",
            "Extract emb for 1462-170142-0035\n",
            "Extract emb for 1462-170142-0037\n",
            "Extract emb for 1462-170142-0036\n",
            "Extract emb for 1462-170142-0042\n",
            "Extract emb for 1462-170142-0038\n",
            "Extract emb for 1462-170145-0003\n",
            "Extract emb for 1462-170145-0002\n",
            "Extract emb for 1462-170145-0007\n",
            "Extract emb for 1462-170145-0004\n",
            "Extract emb for 1462-170145-0001\n",
            "Extract emb for 1462-170145-0008\n",
            "Extract emb for 1462-170145-0005\n",
            "Extract emb for 1462-170145-0000\n",
            "Extract emb for 1462-170145-0006\n",
            "Extract emb for 1462-170145-0013\n",
            "Extract emb for 1462-170145-0015\n",
            "Extract emb for 1462-170145-0017\n",
            "Extract emb for 1462-170145-0018\n",
            "Extract emb for 1462-170145-0020\n",
            "Extract emb for 1462-170145-0011\n",
            "Extract emb for 1462-170145-0010\n",
            "Extract emb for 1462-170145-0014\n",
            "Extract emb for 1462-170145-0009\n",
            "Extract emb for 1462-170145-0012\n",
            "Extract emb for 1462-170145-0016\n",
            "Extract emb for 1462-170145-0019\n",
            "Extract emb for 1462-170145-0021\n",
            "Extract emb for 1673-143397-0003\n",
            "Extract emb for 1673-143397-0000\n",
            "Extract emb for 1673-143397-0001\n",
            "Extract emb for 1673-143397-0002\n",
            "Extract emb for 1462-170145-0022\n",
            "Extract emb for 1673-143397-0007\n",
            "Extract emb for 1673-143397-0004\n",
            "Extract emb for 1673-143397-0005\n",
            "Extract emb for 1673-143397-0006\n",
            "Extract emb for 1673-143397-0008\n",
            "Extract emb for 1673-143397-0009\n",
            "Extract emb for 1673-143397-0010\n",
            "Extract emb for 1673-143397-0013\n",
            "Extract emb for 1673-143397-0012\n",
            "Extract emb for 1673-143397-0011\n",
            "Extract emb for 1673-143397-0015\n",
            "Extract emb for 1673-143397-0016\n",
            "Extract emb for 1673-143397-0014\n",
            "Extract emb for 1673-143397-0017\n",
            "Extract emb for 1673-143397-0018\n",
            "Extract emb for 1673-143397-0020\n",
            "Extract emb for 1673-143397-0019\n",
            "Extract emb for 1919-142785-0000\n",
            "Extract emb for 1919-142785-0001\n",
            "Extract emb for 1919-142785-0003\n",
            "Extract emb for 1919-142785-0006\n",
            "Extract emb for 1919-142785-0004\n",
            "Extract emb for 1919-142785-0005\n",
            "Extract emb for 1919-142785-0002\n",
            "Extract emb for 1919-142785-0007\n",
            "Extract emb for 1919-142785-0008\n",
            "Extract emb for 1919-142785-0012\n",
            "Extract emb for 1919-142785-0011\n",
            "Extract emb for 1919-142785-0014\n",
            "Extract emb for 1919-142785-0010\n",
            "Extract emb for 1919-142785-0009\n",
            "Extract emb for 1919-142785-0013\n",
            "Extract emb for 1919-142785-0017\n",
            "Extract emb for 1919-142785-0020\n",
            "Extract emb for 1919-142785-0018\n",
            "Extract emb for 1919-142785-0021\n",
            "Extract emb for 1919-142785-0019\n",
            "Extract emb for 1919-142785-0016\n",
            "Extract emb for 1919-142785-0015\n",
            "Extract emb for 1919-142785-0022\n",
            "Extract emb for 1919-142785-0025\n",
            "Extract emb for 1919-142785-0029\n",
            "Extract emb for 1919-142785-0026\n",
            "Extract emb for 1919-142785-0023\n",
            "Extract emb for 1919-142785-0028\n",
            "Extract emb for 1919-142785-0024\n",
            "Extract emb for 1919-142785-0027\n",
            "Extract emb for 1919-142785-0031\n",
            "Extract emb for 1919-142785-0030\n",
            "Extract emb for 1919-142785-0034\n",
            "Extract emb for 1919-142785-0033\n",
            "Extract emb for 1919-142785-0032\n",
            "Extract emb for 1919-142785-0036\n",
            "Extract emb for 1919-142785-0035\n",
            "Extract emb for 1919-142785-0042\n",
            "Extract emb for 1919-142785-0043\n",
            "Extract emb for 1919-142785-0039\n",
            "Extract emb for 1919-142785-0038\n",
            "Extract emb for 1919-142785-0040\n",
            "Extract emb for 1919-142785-0041\n",
            "Extract emb for 1919-142785-0037\n",
            "Extract emb for 1919-142785-0044\n",
            "Extract emb for 1919-142785-0046\n",
            "Extract emb for 1919-142785-0048\n",
            "Extract emb for 1919-142785-0047\n",
            "Extract emb for 1919-142785-0045\n",
            "Extract emb for 1919-142785-0050\n",
            "Extract emb for 1919-142785-0051\n",
            "Extract emb for 1919-142785-0052\n",
            "Extract emb for 1919-142785-0054\n",
            "Extract emb for 1919-142785-0049\n",
            "Extract emb for 1919-142785-0053\n",
            "Extract emb for 1919-142785-0055\n",
            "Extract emb for 1919-142785-0057\n",
            "Extract emb for 1919-142785-0056\n",
            "Extract emb for 1919-142785-0060\n",
            "Extract emb for 1919-142785-0059\n",
            "Extract emb for 1919-142785-0058\n",
            "Extract emb for 1919-142785-0062\n",
            "Extract emb for 1919-142785-0061\n",
            "Extract emb for 1919-142785-0063\n",
            "Extract emb for 1988-148538-0001\n",
            "Extract emb for 1988-148538-0002\n",
            "Extract emb for 1988-148538-0000\n",
            "Extract emb for 1988-148538-0005\n",
            "Extract emb for 1988-148538-0003\n",
            "Extract emb for 1988-148538-0004\n",
            "Extract emb for 1988-148538-0007\n",
            "Extract emb for 1988-148538-0008\n",
            "Extract emb for 1988-148538-0010\n",
            "Extract emb for 1988-148538-0009\n",
            "Extract emb for 1988-148538-0006\n",
            "Extract emb for 1988-148538-0013\n",
            "Extract emb for 1988-148538-0014\n",
            "Extract emb for 1988-148538-0012\n",
            "Extract emb for 1988-148538-0011\n",
            "Extract emb for 1988-24833-0006\n",
            "Extract emb for 1988-24833-0003\n",
            "Extract emb for 1988-24833-0001\n",
            "Extract emb for 1988-24833-0004\n",
            "Extract emb for 1988-148538-0015\n",
            "Extract emb for 1988-24833-0005\n",
            "Extract emb for 1988-24833-0000\n",
            "Extract emb for 1988-24833-0002\n",
            "Extract emb for 1988-24833-0014\n",
            "Extract emb for 1988-24833-0007\n",
            "Extract emb for 1988-24833-0015\n",
            "Extract emb for 1988-24833-0013\n",
            "Extract emb for 1988-24833-0008\n",
            "Extract emb for 1988-24833-0009\n",
            "Extract emb for 1988-24833-0010\n",
            "Extract emb for 1988-24833-0012\n",
            "Extract emb for 1988-24833-0011\n",
            "Extract emb for 1988-24833-0016\n",
            "Extract emb for 1988-24833-0022\n",
            "Extract emb for 1988-24833-0020\n",
            "Extract emb for 1988-24833-0019\n",
            "Extract emb for 1988-24833-0023\n",
            "Extract emb for 1988-24833-0021\n",
            "Extract emb for 1988-24833-0025\n",
            "Extract emb for 1988-24833-0018\n",
            "Extract emb for 1988-24833-0024\n",
            "Extract emb for 1988-24833-0017\n",
            "Extract emb for 1988-24833-0026\n",
            "Extract emb for 1993-147964-0004\n",
            "Extract emb for 1988-24833-0028\n",
            "Extract emb for 1988-24833-0027\n",
            "Extract emb for 1993-147964-0000\n",
            "Extract emb for 1993-147964-0003\n",
            "Extract emb for 1993-147964-0001\n",
            "Extract emb for 1993-147964-0002\n",
            "Extract emb for 1993-147964-0007\n",
            "Extract emb for 1993-147964-0006\n",
            "Extract emb for 1993-147964-0009\n",
            "Extract emb for 1993-147964-0005\n",
            "Extract emb for 1993-147964-0008\n",
            "Extract emb for 1993-147965-0000\n",
            "Extract emb for 1993-147965-0001\n",
            "Extract emb for 1993-147965-0003\n",
            "Extract emb for 1993-147964-0010\n",
            "Extract emb for 1993-147965-0005\n",
            "Extract emb for 1993-147965-0002\n",
            "Extract emb for 1993-147965-0004\n",
            "Extract emb for 1993-147966-0001\n",
            "Extract emb for 1993-147965-0006\n",
            "Extract emb for 1993-147965-0007\n",
            "Extract emb for 1993-147966-0000\n",
            "Extract emb for 1993-147965-0008\n",
            "Extract emb for 2035-147961-0002\n",
            "Extract emb for 1993-147966-0003\n",
            "Extract emb for 1993-147966-0004\n",
            "Extract emb for 2035-147961-0000\n",
            "Extract emb for 1993-147966-0006\n",
            "Extract emb for 1993-147966-0002\n",
            "Extract emb for 2035-147961-0003\n",
            "Extract emb for 2035-147961-0001\n",
            "Extract emb for 1993-147966-0005\n",
            "Extract emb for 2035-147961-0005\n",
            "Extract emb for 2035-147961-0004\n",
            "Extract emb for 2035-147961-0008\n",
            "Extract emb for 2035-147961-0011\n",
            "Extract emb for 2035-147961-0009\n",
            "Extract emb for 2035-147961-0006\n",
            "Extract emb for 2035-147961-0010\n",
            "Extract emb for 2035-147961-0012\n",
            "Extract emb for 2035-147961-0007\n",
            "Extract emb for 2035-147961-0013\n",
            "Extract emb for 2035-147961-0015\n",
            "Extract emb for 2035-147961-0020\n",
            "Extract emb for 2035-147961-0022\n",
            "Extract emb for 2035-147961-0014\n",
            "Extract emb for 2035-147961-0019\n",
            "Extract emb for 2035-147961-0017\n",
            "Extract emb for 2035-147961-0018\n",
            "Extract emb for 2035-147961-0021\n",
            "Extract emb for 2035-147961-0016\n",
            "Extract emb for 2035-147961-0027\n",
            "Extract emb for 2035-147961-0023\n",
            "Extract emb for 2035-147961-0025\n",
            "Extract emb for 2035-147961-0031\n",
            "Extract emb for 2035-147961-0026\n",
            "Extract emb for 2035-147961-0024\n",
            "Extract emb for 2035-147961-0028\n",
            "Extract emb for 2035-147961-0029\n",
            "Extract emb for 2035-147961-0030\n",
            "Extract emb for 2035-147961-0034\n",
            "Extract emb for 2035-147961-0038\n",
            "Extract emb for 2035-152373-0000\n",
            "Extract emb for 2035-147961-0033\n",
            "Extract emb for 2035-147961-0035\n",
            "Extract emb for 2035-147961-0040\n",
            "Extract emb for 2035-147961-0039\n",
            "Extract emb for 2035-147961-0032\n",
            "Extract emb for 2035-147961-0037\n",
            "Extract emb for 2035-147961-0036\n",
            "Extract emb for 2035-152373-0001\n",
            "Extract emb for 2035-152373-0004\n",
            "Extract emb for 2035-152373-0003\n",
            "Extract emb for 2035-152373-0002\n",
            "Extract emb for 2035-152373-0005\n",
            "Extract emb for 2035-152373-0006\n",
            "Extract emb for 2035-152373-0007\n",
            "Extract emb for 2035-152373-0008\n",
            "Extract emb for 2035-152373-0010\n",
            "Extract emb for 2035-152373-0011\n",
            "Extract emb for 2035-152373-0009\n",
            "Extract emb for 2035-152373-0013\n",
            "Extract emb for 2035-152373-0015\n",
            "Extract emb for 2035-152373-0016\n",
            "Extract emb for 2035-152373-0014\n",
            "Extract emb for 2035-152373-0012\n",
            "Extract emb for 2277-149896-0002\n",
            "Extract emb for 2277-149896-0001\n",
            "Extract emb for 2277-149896-0000\n",
            "Extract emb for 2277-149896-0005\n",
            "Extract emb for 2035-152373-0018\n",
            "Extract emb for 2277-149896-0006\n",
            "Extract emb for 2277-149896-0003\n",
            "Extract emb for 2035-152373-0017\n",
            "Extract emb for 2277-149896-0004\n",
            "Extract emb for 2277-149896-0013\n",
            "Extract emb for 2277-149896-0009\n",
            "Extract emb for 2277-149896-0015\n",
            "Extract emb for 2277-149896-0011\n",
            "Extract emb for 2277-149896-0008\n",
            "Extract emb for 2277-149896-0014\n",
            "Extract emb for 2277-149896-0007\n",
            "Extract emb for 2277-149896-0010\n",
            "Extract emb for 2277-149896-0012\n",
            "Extract emb for 2277-149896-0025\n",
            "Extract emb for 2277-149896-0017\n",
            "Extract emb for 2277-149896-0021\n",
            "Extract emb for 2277-149896-0019\n",
            "Extract emb for 2277-149896-0024\n",
            "Extract emb for 2277-149896-0022\n",
            "Extract emb for 2277-149896-0018\n",
            "Extract emb for 2277-149896-0016\n",
            "Extract emb for 2277-149896-0023\n",
            "Extract emb for 2277-149896-0020\n",
            "Extract emb for 2277-149896-0031\n",
            "Extract emb for 2277-149896-0026\n",
            "Extract emb for 2277-149896-0032\n",
            "Extract emb for 2277-149896-0030\n",
            "Extract emb for 2277-149896-0029\n",
            "Extract emb for 2277-149896-0033\n",
            "Extract emb for 2277-149896-0028\n",
            "Extract emb for 2277-149896-0034\n",
            "Extract emb for 2277-149896-0027\n",
            "Extract emb for 2277-149897-0000\n",
            "Extract emb for 2277-149897-0004\n",
            "Extract emb for 2277-149897-0005\n",
            "Extract emb for 2277-149897-0002\n",
            "Extract emb for 2277-149897-0001\n",
            "Extract emb for 2277-149897-0007\n",
            "Extract emb for 2277-149897-0006\n",
            "Extract emb for 2277-149897-0003\n",
            "Extract emb for 2277-149897-0011\n",
            "Extract emb for 2277-149897-0014\n",
            "Extract emb for 2277-149897-0010\n",
            "Extract emb for 2277-149897-0017\n",
            "Extract emb for 2277-149897-0015\n",
            "Extract emb for 2277-149897-0013\n",
            "Extract emb for 2277-149897-0012\n",
            "Extract emb for 2277-149897-0009\n",
            "Extract emb for 2277-149897-0016\n",
            "Extract emb for 2277-149897-0008\n",
            "Extract emb for 2277-149897-0025\n",
            "Extract emb for 2277-149897-0023\n",
            "Extract emb for 2277-149897-0021\n",
            "Extract emb for 2277-149897-0024\n",
            "Extract emb for 2277-149897-0022\n",
            "Extract emb for 2277-149897-0018\n",
            "Extract emb for 2277-149897-0020\n",
            "Extract emb for 2277-149897-0019\n",
            "Extract emb for 2277-149897-0029\n",
            "Extract emb for 2277-149897-0033\n",
            "Extract emb for 2277-149897-0027\n",
            "Extract emb for 2277-149897-0026\n",
            "Extract emb for 2277-149897-0032\n",
            "Extract emb for 2277-149897-0028\n",
            "Extract emb for 2277-149897-0031\n",
            "Extract emb for 2277-149897-0030\n",
            "Extract emb for 2277-149897-0035\n",
            "Extract emb for 2277-149897-0036\n",
            "Extract emb for 2277-149897-0037\n",
            "Extract emb for 2412-153948-0001\n",
            "Extract emb for 2412-153948-0000\n",
            "Extract emb for 2277-149897-0034\n",
            "Extract emb for 2412-153948-0002\n",
            "Extract emb for 2412-153948-0003\n",
            "Extract emb for 2412-153948-0004\n",
            "Extract emb for 2412-153948-0005\n",
            "Extract emb for 2412-153948-0008\n",
            "Extract emb for 2412-153948-0007\n",
            "Extract emb for 2412-153948-0010\n",
            "Extract emb for 2412-153948-0009\n",
            "Extract emb for 2412-153948-0006\n",
            "Extract emb for 2412-153948-0011\n",
            "Extract emb for 2412-153948-0013\n",
            "Extract emb for 2412-153948-0015\n",
            "Extract emb for 2412-153954-0002\n",
            "Extract emb for 2412-153948-0012\n",
            "Extract emb for 2412-153954-0000\n",
            "Extract emb for 2412-153948-0014\n",
            "Extract emb for 2412-153954-0001\n",
            "Extract emb for 2412-153954-0006\n",
            "Extract emb for 2412-153954-0005\n",
            "Extract emb for 2412-153954-0003\n",
            "Extract emb for 2412-153954-0004\n",
            "Extract emb for 2412-153954-0008\n",
            "Extract emb for 2412-153954-0007\n",
            "Extract emb for 2412-153954-0012\n",
            "Extract emb for 2412-153954-0009\n",
            "Extract emb for 2412-153954-0011\n",
            "Extract emb for 2412-153954-0013\n",
            "Extract emb for 2412-153954-0010\n",
            "Extract emb for 2412-153954-0017\n",
            "Extract emb for 2412-153954-0014\n",
            "Extract emb for 2412-153954-0016\n",
            "Extract emb for 2412-153954-0015\n",
            "Extract emb for 2412-153954-0018\n",
            "Extract emb for 2412-153954-0021\n",
            "Extract emb for 2412-153954-0023\n",
            "Extract emb for 2412-153954-0024\n",
            "Extract emb for 3081-166546-0000\n",
            "Extract emb for 2412-153954-0022\n",
            "Extract emb for 2412-153954-0019\n",
            "Extract emb for 2412-153954-0020\n",
            "Extract emb for 3081-166546-0009\n",
            "Extract emb for 3081-166546-0010\n",
            "Extract emb for 3081-166546-0006\n",
            "Extract emb for 3081-166546-0001\n",
            "Extract emb for 3081-166546-0008\n",
            "Extract emb for 3081-166546-0005\n",
            "Extract emb for 3081-166546-0004\n",
            "Extract emb for 3081-166546-0003\n",
            "Extract emb for 3081-166546-0002\n",
            "Extract emb for 3081-166546-0007\n",
            "Extract emb for 3081-166546-0018\n",
            "Extract emb for 3081-166546-0015\n",
            "Extract emb for 3081-166546-0011\n",
            "Extract emb for 3081-166546-0014\n",
            "Extract emb for 3081-166546-0013\n",
            "Extract emb for 3081-166546-0016\n",
            "Extract emb for 3081-166546-0012\n",
            "Extract emb for 3081-166546-0017\n",
            "Extract emb for 3081-166546-0024\n",
            "Extract emb for 3081-166546-0019\n",
            "Extract emb for 3081-166546-0020\n",
            "Extract emb for 3081-166546-0022\n",
            "Extract emb for 3081-166546-0023\n",
            "Extract emb for 3081-166546-0025\n",
            "Extract emb for 3081-166546-0021\n",
            "Extract emb for 3081-166546-0026\n",
            "Extract emb for 3081-166546-0030\n",
            "Extract emb for 3081-166546-0029\n",
            "Extract emb for 3081-166546-0028\n",
            "Extract emb for 3081-166546-0027\n",
            "Extract emb for 3081-166546-0032\n",
            "Extract emb for 3081-166546-0036\n",
            "Extract emb for 3081-166546-0031\n",
            "Extract emb for 3081-166546-0039\n",
            "Extract emb for 3081-166546-0034\n",
            "Extract emb for 3081-166546-0038\n",
            "Extract emb for 3081-166546-0033\n",
            "Extract emb for 3081-166546-0035\n",
            "Extract emb for 3081-166546-0037\n",
            "Extract emb for 3081-166546-0041\n",
            "Extract emb for 3081-166546-0043\n",
            "Extract emb for 3081-166546-0044\n",
            "Extract emb for 3081-166546-0045\n",
            "Extract emb for 3081-166546-0042\n",
            "Extract emb for 3081-166546-0046\n",
            "Extract emb for 3081-166546-0040\n",
            "Extract emb for 3081-166546-0050\n",
            "Extract emb for 3081-166546-0047\n",
            "Extract emb for 3081-166546-0052\n",
            "Extract emb for 3081-166546-0048\n",
            "Extract emb for 3081-166546-0053\n",
            "Extract emb for 3081-166546-0054\n",
            "Extract emb for 3081-166546-0051\n",
            "Extract emb for 3081-166546-0049\n",
            "Extract emb for 3081-166546-0061\n",
            "Extract emb for 3081-166546-0055\n",
            "Extract emb for 3081-166546-0058\n",
            "Extract emb for 3081-166546-0059\n",
            "Extract emb for 3081-166546-0060\n",
            "Extract emb for 3081-166546-0056\n",
            "Extract emb for 3081-166546-0057\n",
            "Extract emb for 3081-166546-0062\n",
            "Extract emb for 3081-166546-0064\n",
            "Extract emb for 3081-166546-0068\n",
            "Extract emb for 3081-166546-0063\n",
            "Extract emb for 3081-166546-0069\n",
            "Extract emb for 3081-166546-0066\n",
            "Extract emb for 3081-166546-0065\n",
            "Extract emb for 3081-166546-0067\n",
            "Extract emb for 3081-166546-0072\n",
            "Extract emb for 3081-166546-0073\n",
            "Extract emb for 3081-166546-0076\n",
            "Extract emb for 3081-166546-0074\n",
            "Extract emb for 3081-166546-0071\n",
            "Extract emb for 3081-166546-0070\n",
            "Extract emb for 3081-166546-0075\n",
            "Extract emb for 3081-166546-0080\n",
            "Extract emb for 3081-166546-0083\n",
            "Extract emb for 3081-166546-0082\n",
            "Extract emb for 3081-166546-0078\n",
            "Extract emb for 3081-166546-0084\n",
            "Extract emb for 3081-166546-0081\n",
            "Extract emb for 3081-166546-0079\n",
            "Extract emb for 3081-166546-0077\n",
            "Extract emb for 3081-166546-0085\n",
            "Extract emb for 3081-166546-0087\n",
            "Extract emb for 3081-166546-0088\n",
            "Extract emb for 3081-166546-0086\n",
            "Extract emb for 3536-8226-0000\n",
            "Extract emb for 3081-166546-0089\n",
            "Extract emb for 3536-8226-0001\n",
            "Extract emb for 3536-8226-0002\n",
            "Extract emb for 3536-8226-0003\n",
            "Extract emb for 3536-8226-0004\n",
            "Extract emb for 3536-8226-0005\n",
            "Extract emb for 3536-8226-0014\n",
            "Extract emb for 3536-8226-0010\n",
            "Extract emb for 3536-8226-0012\n",
            "Extract emb for 3536-8226-0013\n",
            "Extract emb for 3536-8226-0008\n",
            "Extract emb for 3536-8226-0011\n",
            "Extract emb for 3536-8226-0007\n",
            "Extract emb for 3536-8226-0009\n",
            "Extract emb for 3536-8226-0006\n",
            "Extract emb for 3536-8226-0019\n",
            "Extract emb for 3536-8226-0015\n",
            "Extract emb for 3536-8226-0017\n",
            "Extract emb for 3536-8226-0020\n",
            "Extract emb for 3536-8226-0021\n",
            "Extract emb for 3536-8226-0018\n",
            "Extract emb for 3536-8226-0016\n",
            "Extract emb for 3536-8226-0023\n",
            "Extract emb for 3536-8226-0025\n",
            "Extract emb for 3536-8226-0027\n",
            "Extract emb for 3536-8226-0026\n",
            "Extract emb for 3536-8226-0022\n",
            "Extract emb for 3536-8226-0024\n",
            "Extract emb for 3536-8226-0028\n",
            "Extract emb for 3536-8226-0029\n",
            "Extract emb for 3536-8226-0032\n",
            "Extract emb for 3536-8226-0030\n",
            "Extract emb for 3576-138058-0001\n",
            "Extract emb for 3536-8226-0031\n",
            "Extract emb for 3576-138058-0000\n",
            "Extract emb for 3576-138058-0004\n",
            "Extract emb for 3576-138058-0003\n",
            "Extract emb for 3576-138058-0002\n",
            "Extract emb for 3576-138058-0005\n",
            "Extract emb for 3576-138058-0009\n",
            "Extract emb for 3576-138058-0008\n",
            "Extract emb for 3576-138058-0006\n",
            "Extract emb for 3576-138058-0007\n",
            "Extract emb for 3576-138058-0011\n",
            "Extract emb for 3576-138058-0013\n",
            "Extract emb for 3576-138058-0012\n",
            "Extract emb for 3576-138058-0010\n",
            "Extract emb for 3576-138058-0016\n",
            "Extract emb for 3576-138058-0015\n",
            "Extract emb for 3576-138058-0014\n",
            "Extract emb for 3576-138058-0018\n",
            "Extract emb for 3576-138058-0017\n",
            "Extract emb for 3576-138058-0019\n",
            "Extract emb for 3576-138058-0020\n",
            "Extract emb for 3576-138058-0022\n",
            "Extract emb for 3576-138058-0021\n",
            "Extract emb for 3576-138058-0023\n",
            "Extract emb for 3576-138058-0026\n",
            "Extract emb for 3576-138058-0024\n",
            "Extract emb for 3576-138058-0025\n",
            "Extract emb for 3576-138058-0031\n",
            "Extract emb for 3576-138058-0032\n",
            "Extract emb for 3576-138058-0028\n",
            "Extract emb for 3576-138058-0030\n",
            "Extract emb for 3576-138058-0029\n",
            "Extract emb for 3576-138058-0027\n",
            "Extract emb for 3576-138058-0034\n",
            "Extract emb for 3576-138058-0033\n",
            "Extract emb for 3576-138058-0037\n",
            "Extract emb for 3576-138058-0038\n",
            "Extract emb for 3576-138058-0036\n",
            "Extract emb for 3576-138058-0035\n",
            "Extract emb for 3853-163249-0002\n",
            "Extract emb for 3853-163249-0000\n",
            "Extract emb for 3853-163249-0001\n",
            "Extract emb for 3576-138058-0040\n",
            "Extract emb for 3576-138058-0039\n",
            "Extract emb for 3853-163249-0008\n",
            "Extract emb for 3853-163249-0006\n",
            "Extract emb for 3853-163249-0005\n",
            "Extract emb for 3853-163249-0007\n",
            "Extract emb for 3853-163249-0003\n",
            "Extract emb for 3853-163249-0009\n",
            "Extract emb for 3853-163249-0004\n",
            "Extract emb for 3853-163249-0010\n",
            "Extract emb for 3853-163249-0015\n",
            "Extract emb for 3853-163249-0013\n",
            "Extract emb for 3853-163249-0011\n",
            "Extract emb for 3853-163249-0012\n",
            "Extract emb for 3853-163249-0014\n",
            "Extract emb for 3853-163249-0016\n",
            "Extract emb for 3853-163249-0018\n",
            "Extract emb for 3853-163249-0017\n",
            "Extract emb for 3853-163249-0019\n",
            "Extract emb for 3853-163249-0022\n",
            "Extract emb for 3853-163249-0025\n",
            "Extract emb for 3853-163249-0021\n",
            "Extract emb for 3853-163249-0023\n",
            "Extract emb for 3853-163249-0020\n",
            "Extract emb for 3853-163249-0024\n",
            "Extract emb for 3853-163249-0027\n",
            "Extract emb for 3853-163249-0028\n",
            "Extract emb for 3853-163249-0026\n",
            "Extract emb for 3853-163249-0029\n",
            "Extract emb for 3853-163249-0030\n",
            "Extract emb for 3853-163249-0033\n",
            "Extract emb for 3853-163249-0031\n",
            "Extract emb for 3853-163249-0035\n",
            "Extract emb for 3853-163249-0034\n",
            "Extract emb for 3853-163249-0032\n",
            "Extract emb for 3853-163249-0039\n",
            "Extract emb for 3853-163249-0040\n",
            "Extract emb for 3853-163249-0041\n",
            "Extract emb for 3853-163249-0037\n",
            "Extract emb for 3853-163249-0038\n",
            "Extract emb for 3853-163249-0036\n",
            "Extract emb for 3853-163249-0044\n",
            "Extract emb for 3853-163249-0043\n",
            "Extract emb for 3853-163249-0045\n",
            "Extract emb for 3853-163249-0042\n",
            "Extract emb for 3853-163249-0047\n",
            "Extract emb for 3853-163249-0046\n",
            "Extract emb for 3853-163249-0049\n",
            "Extract emb for 3853-163249-0048\n",
            "Extract emb for 3853-163249-0050\n",
            "Extract emb for 3853-163249-0053\n",
            "Extract emb for 3853-163249-0052\n",
            "Extract emb for 3853-163249-0051\n",
            "Extract emb for 3853-163249-0056\n",
            "Extract emb for 5338-24640-0001\n",
            "Extract emb for 3853-163249-0055\n",
            "Extract emb for 3853-163249-0054\n",
            "Extract emb for 5338-24640-0000\n",
            "Extract emb for 5338-24640-0002\n",
            "Extract emb for 5338-24640-0006\n",
            "Extract emb for 5338-24640-0005\n",
            "Extract emb for 5338-24640-0003\n",
            "Extract emb for 5338-24640-0004\n",
            "Extract emb for 5338-284437-0001\n",
            "Extract emb for 5338-24640-0009\n",
            "Extract emb for 5338-284437-0000\n",
            "Extract emb for 5338-24640-0008\n",
            "Extract emb for 5338-284437-0002\n",
            "Extract emb for 5338-24640-0007\n",
            "Extract emb for 5338-284437-0004\n",
            "Extract emb for 5338-284437-0006\n",
            "Extract emb for 5338-284437-0003\n",
            "Extract emb for 5338-284437-0009\n",
            "Extract emb for 5338-284437-0008\n",
            "Extract emb for 5338-284437-0005\n",
            "Extract emb for 5338-284437-0007\n",
            "Extract emb for 5338-284437-0013\n",
            "Extract emb for 5338-284437-0018\n",
            "Extract emb for 5338-284437-0012\n",
            "Extract emb for 5338-284437-0011\n",
            "Extract emb for 5338-284437-0016\n",
            "Extract emb for 5338-284437-0017\n",
            "Extract emb for 5338-284437-0015\n",
            "Extract emb for 5338-284437-0010\n",
            "Extract emb for 5338-284437-0014\n",
            "Extract emb for 5338-284437-0019\n",
            "Extract emb for 5338-284437-0023\n",
            "Extract emb for 5338-284437-0024\n",
            "Extract emb for 5338-284437-0020\n",
            "Extract emb for 5338-284437-0025\n",
            "Extract emb for 5338-284437-0022\n",
            "Extract emb for 5338-284437-0021\n",
            "Extract emb for 5338-284437-0031\n",
            "Extract emb for 5338-284437-0030\n",
            "Extract emb for 5338-284437-0026\n",
            "Extract emb for 5338-284437-0027\n",
            "Extract emb for 5338-284437-0029\n",
            "Extract emb for 5338-284437-0028\n",
            "Extract emb for 5895-34622-0006\n",
            "Extract emb for 5895-34622-0002\n",
            "Extract emb for 5338-284437-0032\n",
            "Extract emb for 5895-34622-0003\n",
            "Extract emb for 5895-34622-0000\n",
            "Extract emb for 5895-34622-0005\n",
            "Extract emb for 5895-34622-0004\n",
            "Extract emb for 5338-284437-0033\n",
            "Extract emb for 5895-34622-0001\n",
            "Extract emb for 5895-34622-0010\n",
            "Extract emb for 5895-34622-0009\n",
            "Extract emb for 5895-34622-0012\n",
            "Extract emb for 5895-34622-0008\n",
            "Extract emb for 5895-34622-0011\n",
            "Extract emb for 5895-34622-0007\n",
            "Extract emb for 5895-34622-0017\n",
            "Extract emb for 5895-34622-0018\n",
            "Extract emb for 5895-34622-0019\n",
            "Extract emb for 5895-34622-0015\n",
            "Extract emb for 5895-34622-0013\n",
            "Extract emb for 5895-34622-0016\n",
            "Extract emb for 5895-34622-0014\n",
            "Extract emb for 5895-34622-0023\n",
            "Extract emb for 5895-34629-0000\n",
            "Extract emb for 5895-34629-0004\n",
            "Extract emb for 5895-34629-0001\n",
            "Extract emb for 5895-34629-0002\n",
            "Extract emb for 5895-34622-0022\n",
            "Extract emb for 5895-34622-0020\n",
            "Extract emb for 5895-34622-0021\n",
            "Extract emb for 5895-34629-0003\n",
            "Extract emb for 5895-34629-0005\n",
            "Extract emb for 5895-34629-0010\n",
            "Extract emb for 5895-34629-0008\n",
            "Extract emb for 5895-34629-0012\n",
            "Extract emb for 5895-34629-0011\n",
            "Extract emb for 5895-34629-0009\n",
            "Extract emb for 5895-34629-0007\n",
            "Extract emb for 5895-34629-0006\n",
            "Extract emb for 5895-34629-0016\n",
            "Extract emb for 5895-34629-0013\n",
            "Extract emb for 5895-34629-0014\n",
            "Extract emb for 5895-34629-0017\n",
            "Extract emb for 5895-34629-0019\n",
            "Extract emb for 5895-34629-0021\n",
            "Extract emb for 5895-34629-0018\n",
            "Extract emb for 5895-34629-0020\n",
            "Extract emb for 5895-34629-0015\n",
            "Extract emb for 5895-34629-0025\n",
            "Extract emb for 5895-34629-0023\n",
            "Extract emb for 5895-34629-0022\n",
            "Extract emb for 5895-34629-0026\n",
            "Extract emb for 5895-34629-0024\n",
            "Extract emb for 5895-34629-0027\n",
            "Extract emb for 6313-66129-0000\n",
            "Extract emb for 5895-34629-0033\n",
            "Extract emb for 5895-34629-0031\n",
            "Extract emb for 5895-34629-0028\n",
            "Extract emb for 5895-34629-0030\n",
            "Extract emb for 5895-34629-0029\n",
            "Extract emb for 6313-66129-0001\n",
            "Extract emb for 5895-34629-0032\n",
            "Extract emb for 6313-66129-0008\n",
            "Extract emb for 6313-66129-0003\n",
            "Extract emb for 6313-66129-0002\n",
            "Extract emb for 6313-66129-0004\n",
            "Extract emb for 6313-66129-0007\n",
            "Extract emb for 6313-66129-0010\n",
            "Extract emb for 6313-66129-0005\n",
            "Extract emb for 6313-66129-0006\n",
            "Extract emb for 6313-66129-0009\n",
            "Extract emb for 6313-66129-0011\n",
            "Extract emb for 6313-66129-0016\n",
            "Extract emb for 6313-66129-0018\n",
            "Extract emb for 6313-66129-0017\n",
            "Extract emb for 6313-66129-0013\n",
            "Extract emb for 6313-66129-0015\n",
            "Extract emb for 6313-66129-0014\n",
            "Extract emb for 6313-66129-0012\n",
            "Extract emb for 6313-66129-0023\n",
            "Extract emb for 6313-66129-0025\n",
            "Extract emb for 6313-66129-0019\n",
            "Extract emb for 6313-66129-0020\n",
            "Extract emb for 6313-66129-0021\n",
            "Extract emb for 6313-66129-0024\n",
            "Extract emb for 6313-66129-0022\n",
            "Extract emb for 6313-66129-0030\n",
            "Extract emb for 6313-66129-0027\n",
            "Extract emb for 6313-66129-0029\n",
            "Extract emb for 6313-66129-0026\n",
            "Extract emb for 6313-66129-0032\n",
            "Extract emb for 6313-66129-0031\n",
            "Extract emb for 6313-66129-0028\n",
            "Extract emb for 6313-76958-0000\n",
            "Extract emb for 6313-66129-0035\n",
            "Extract emb for 6313-76958-0001\n",
            "Extract emb for 6313-76958-0004\n",
            "Extract emb for 6313-76958-0006\n",
            "Extract emb for 6313-66129-0034\n",
            "Extract emb for 6313-76958-0005\n",
            "Extract emb for 6313-76958-0002\n",
            "Extract emb for 6313-66129-0033\n",
            "Extract emb for 6313-76958-0003\n",
            "Extract emb for 6313-76958-0011\n",
            "Extract emb for 6313-76958-0007\n",
            "Extract emb for 6313-76958-0009\n",
            "Extract emb for 6313-76958-0013\n",
            "Extract emb for 6313-76958-0010\n",
            "Extract emb for 6313-76958-0008\n",
            "Extract emb for 6313-76958-0012\n",
            "Extract emb for 6313-76958-0015\n",
            "Extract emb for 6313-76958-0014\n",
            "Extract emb for 6313-76958-0019\n",
            "Extract emb for 6313-76958-0017\n",
            "Extract emb for 6313-76958-0018\n",
            "Extract emb for 6313-76958-0020\n",
            "Extract emb for 6313-76958-0016\n",
            "Extract emb for 6313-76958-0023\n",
            "Extract emb for 6313-76958-0028\n",
            "Extract emb for 6313-76958-0025\n",
            "Extract emb for 6313-76958-0024\n",
            "Extract emb for 6313-76958-0022\n",
            "Extract emb for 6313-76958-0030\n",
            "Extract emb for 6313-76958-0031\n",
            "Extract emb for 6313-76958-0029\n",
            "Extract emb for 6313-76958-0026\n",
            "Extract emb for 6313-76958-0021\n",
            "Extract emb for 6313-76958-0027\n",
            "Extract emb for 6319-57405-0001\n",
            "Extract emb for 6319-57405-0000\n",
            "Extract emb for 6319-57405-0002\n",
            "Extract emb for 6319-57405-0004\n",
            "Extract emb for 6319-57405-0005\n",
            "Extract emb for 6319-57405-0003\n",
            "Extract emb for 6319-57405-0007\n",
            "Extract emb for 6319-57405-0008\n",
            "Extract emb for 6319-57405-0009\n",
            "Extract emb for 6319-57405-0006\n",
            "Extract emb for 6319-57405-0010\n",
            "Extract emb for 6319-57405-0012\n",
            "Extract emb for 6319-64726-0000\n",
            "Extract emb for 6319-57405-0011\n",
            "Extract emb for 6319-64726-0001\n",
            "Extract emb for 6319-64726-0004\n",
            "Extract emb for 6319-64726-0003\n",
            "Extract emb for 6319-64726-0005\n",
            "Extract emb for 6319-64726-0002\n",
            "Extract emb for 6319-64726-0006\n",
            "Extract emb for 6319-64726-0007\n",
            "Extract emb for 6319-64726-0011\n",
            "Extract emb for 6319-64726-0010\n",
            "Extract emb for 6319-64726-0009\n",
            "Extract emb for 6319-64726-0008\n",
            "Extract emb for 6319-64726-0014\n",
            "Extract emb for 6319-64726-0017\n",
            "Extract emb for 6319-64726-0012\n",
            "Extract emb for 6319-64726-0016\n",
            "Extract emb for 6319-64726-0018\n",
            "Extract emb for 6319-64726-0015\n",
            "Extract emb for 6319-64726-0013\n",
            "Extract emb for 6345-93302-0002\n",
            "Extract emb for 6345-93302-0000\n",
            "Extract emb for 6319-64726-0019\n",
            "Extract emb for 6345-93302-0001\n",
            "Extract emb for 6319-64726-0020\n",
            "Extract emb for 6345-93302-0010\n",
            "Extract emb for 6345-93302-0003\n",
            "Extract emb for 6345-93302-0011\n",
            "Extract emb for 6345-93302-0006\n",
            "Extract emb for 6345-93302-0004\n",
            "Extract emb for 6345-93302-0008\n",
            "Extract emb for 6345-93302-0007\n",
            "Extract emb for 6345-93302-0005\n",
            "Extract emb for 6345-93302-0009\n",
            "Extract emb for 6345-93302-0014\n",
            "Extract emb for 6345-93302-0017\n",
            "Extract emb for 6345-93302-0019\n",
            "Extract emb for 6345-93302-0015\n",
            "Extract emb for 6345-93302-0013\n",
            "Extract emb for 6345-93302-0012\n",
            "Extract emb for 6345-93302-0018\n",
            "Extract emb for 6345-93302-0016\n",
            "Extract emb for 6345-93302-0021\n",
            "Extract emb for 6345-93302-0022\n",
            "Extract emb for 6345-93302-0023\n",
            "Extract emb for 6345-93302-0025\n",
            "Extract emb for 6345-93302-0020\n",
            "Extract emb for 6345-93302-0024\n",
            "Extract emb for 6345-93302-0028\n",
            "Extract emb for 6345-93302-0026\n",
            "Extract emb for 6345-93302-0027\n",
            "Extract emb for 6345-93302-0029\n",
            "Extract emb for 6345-93306-0000\n",
            "Extract emb for 6345-93306-0005\n",
            "Extract emb for 6345-93306-0006\n",
            "Extract emb for 6345-93306-0007\n",
            "Extract emb for 6345-93306-0008\n",
            "Extract emb for 6345-93306-0003\n",
            "Extract emb for 6345-93306-0001\n",
            "Extract emb for 6345-93306-0004\n",
            "Extract emb for 6345-93306-0002\n",
            "Extract emb for 6345-93306-0009\n",
            "Extract emb for 6345-93306-0012\n",
            "Extract emb for 6345-93306-0010\n",
            "Extract emb for 6345-93306-0015\n",
            "Extract emb for 6345-93306-0016\n",
            "Extract emb for 6345-93306-0014\n",
            "Extract emb for 6345-93306-0013\n",
            "Extract emb for 6345-93306-0017\n",
            "Extract emb for 6345-93306-0011\n",
            "Extract emb for 6345-93306-0018\n",
            "Extract emb for 6345-93306-0022\n",
            "Extract emb for 6345-93306-0020\n",
            "Extract emb for 6345-93306-0019\n",
            "Extract emb for 6345-93306-0021\n",
            "Extract emb for 6345-93306-0024\n",
            "Extract emb for 7850-281318-0001\n",
            "Extract emb for 6345-93306-0023\n",
            "Extract emb for 7850-281318-0000\n",
            "Extract emb for 7850-281318-0002\n",
            "Extract emb for 6345-93306-0025\n",
            "Extract emb for 7850-281318-0006\n",
            "Extract emb for 7850-281318-0004\n",
            "Extract emb for 7850-281318-0005\n",
            "Extract emb for 7850-281318-0003\n",
            "Extract emb for 7850-281318-0009\n",
            "Extract emb for 7850-281318-0007\n",
            "Extract emb for 7850-281318-0008\n",
            "Extract emb for 7850-281318-0013\n",
            "Extract emb for 7850-281318-0010\n",
            "Extract emb for 7850-281318-0014\n",
            "Extract emb for 7850-281318-0015\n",
            "Extract emb for 7850-281318-0011\n",
            "Extract emb for 7850-281318-0012\n",
            "Extract emb for 7850-281318-0022\n",
            "Extract emb for 7850-281318-0017\n",
            "Extract emb for 7850-281318-0021\n",
            "Extract emb for 7850-281318-0018\n",
            "Extract emb for 7850-281318-0019\n",
            "Extract emb for 7850-281318-0016\n",
            "Extract emb for 7850-281318-0020\n",
            "Extract emb for 7850-286674-0002\n",
            "Extract emb for 7850-281318-0023\n",
            "Extract emb for 7850-286674-0004\n",
            "Extract emb for 7850-286674-0001\n",
            "Extract emb for 7850-286674-0000\n",
            "Extract emb for 7850-286674-0003\n",
            "Extract emb for 7850-286674-0008\n",
            "Extract emb for 7850-286674-0006\n",
            "Extract emb for 7850-286674-0010\n",
            "Extract emb for 7850-286674-0011\n",
            "Extract emb for 7850-286674-0005\n",
            "Extract emb for 7850-286674-0007\n",
            "Extract emb for 7850-286674-0009\n",
            "Extract emb for 7850-286674-0017\n",
            "Extract emb for 7850-286674-0014\n",
            "Extract emb for 7850-286674-0013\n",
            "Extract emb for 7850-286674-0015\n",
            "Extract emb for 7850-73752-0000\n",
            "Extract emb for 7850-286674-0012\n",
            "Extract emb for 7850-286674-0016\n",
            "Extract emb for 7850-73752-0004\n",
            "Extract emb for 7850-73752-0001\n",
            "Extract emb for 7850-73752-0005\n",
            "Extract emb for 7850-73752-0003\n",
            "Extract emb for 7850-73752-0002\n",
            "Extract emb for 7850-73752-0006\n",
            "Extract emb for 7850-73752-0008\n",
            "Extract emb for 7850-73752-0009\n",
            "Extract emb for 7850-73752-0007\n",
            "Extract emb for 7850-73752-0015\n",
            "Extract emb for 7850-73752-0010\n",
            "Extract emb for 7850-73752-0014\n",
            "Extract emb for 7850-73752-0012\n",
            "Extract emb for 7850-73752-0016\n",
            "Extract emb for 7850-73752-0011\n",
            "Extract emb for 7850-73752-0017\n",
            "Extract emb for 7850-73752-0013\n",
            "Extract emb for 84-121550-0000\n",
            "Extract emb for 7850-73752-0019\n",
            "Extract emb for 7850-73752-0018\n",
            "Extract emb for 84-121550-0005\n",
            "Extract emb for 84-121550-0004\n",
            "Extract emb for 84-121550-0003\n",
            "Extract emb for 84-121550-0002\n",
            "Extract emb for 84-121550-0006\n",
            "Extract emb for 84-121550-0001\n",
            "Extract emb for 84-121550-0008\n",
            "Extract emb for 84-121550-0009\n",
            "Extract emb for 84-121550-0007\n",
            "Extract emb for 84-121550-0011\n",
            "Extract emb for 84-121550-0010\n",
            "Extract emb for 84-121550-0015\n",
            "Extract emb for 84-121550-0014\n",
            "Extract emb for 84-121550-0012\n",
            "Extract emb for 84-121550-0013\n",
            "Extract emb for 84-121550-0018\n",
            "Extract emb for 84-121550-0017\n",
            "Extract emb for 84-121550-0016\n",
            "Extract emb for 84-121550-0019\n",
            "Extract emb for 84-121550-0023\n",
            "Extract emb for 84-121550-0021\n",
            "Extract emb for 84-121550-0022\n",
            "Extract emb for 84-121550-0020\n",
            "Extract emb for 84-121550-0025\n",
            "Extract emb for 84-121550-0024\n",
            "Extract emb for 84-121550-0028\n",
            "Extract emb for 84-121550-0027\n",
            "Extract emb for 84-121550-0026\n",
            "Extract emb for 84-121550-0030\n",
            "Extract emb for 84-121550-0031\n",
            "Extract emb for 84-121550-0032\n",
            "Extract emb for 84-121550-0033\n",
            "Extract emb for 84-121550-0029\n",
            "Extract emb for 8842-302201-0001\n",
            "Extract emb for 84-121550-0035\n",
            "Extract emb for 8842-302201-0000\n",
            "Extract emb for 84-121550-0034\n",
            "Extract emb for 8842-302201-0002\n",
            "Extract emb for 8842-302201-0003\n",
            "Extract emb for 8842-302201-0004\n",
            "Extract emb for 8842-302201-0005\n",
            "Extract emb for 8842-302201-0012\n",
            "Extract emb for 8842-302201-0006\n",
            "Extract emb for 8842-302201-0009\n",
            "Extract emb for 8842-302201-0007\n",
            "Extract emb for 8842-302201-0008\n",
            "Extract emb for 8842-302201-0010\n",
            "Extract emb for 8842-302201-0011\n",
            "Extract emb for 8842-302203-0000\n",
            "Extract emb for 8842-302201-0013\n",
            "Extract emb for 8842-302201-0014\n",
            "Extract emb for 8842-302201-0015\n",
            "Extract emb for 8842-302203-0001\n",
            "Extract emb for 8842-302203-0002\n",
            "Extract emb for 8842-302203-0003\n",
            "Extract emb for 8842-302203-0008\n",
            "Extract emb for 8842-302203-0007\n",
            "Extract emb for 8842-302203-0004\n",
            "Extract emb for 8842-302203-0006\n",
            "Extract emb for 8842-302203-0005\n",
            "Extract emb for 8842-304647-0000\n",
            "Extract emb for 8842-302203-0011\n",
            "Extract emb for 8842-302203-0010\n",
            "Extract emb for 8842-302203-0009\n",
            "Extract emb for 8842-304647-0001\n",
            "Extract emb for 8842-304647-0002\n",
            "Extract emb for 8842-304647-0004\n",
            "Extract emb for 8842-304647-0003\n",
            "Extract emb for 8842-304647-0005\n",
            "Extract emb for 8842-304647-0008\n",
            "Extract emb for 8842-304647-0009\n",
            "Extract emb for 8842-304647-0006\n",
            "Extract emb for 8842-304647-0007\n",
            "Extract emb for 8842-304647-0013\n",
            "Extract emb for 8842-304647-0012\n",
            "Extract emb for 8842-304647-0010\n",
            "Extract emb for 8842-304647-0011\n",
            "Extract emb for 1462-170142-0002\n",
            "Extract emb for 1462-170142-0003\n",
            "Extract emb for 1462-170142-0000\n",
            "Extract emb for 1462-170142-0004\n",
            "Extract emb for 1462-170142-0001\n",
            "Extract emb for 1462-170142-0008\n",
            "Extract emb for 1462-170142-0013\n",
            "Extract emb for 1462-170142-0010\n",
            "Extract emb for 1462-170142-0009\n",
            "Extract emb for 1462-170142-0012\n",
            "Extract emb for 1462-170142-0014\n",
            "Extract emb for 1462-170142-0006\n",
            "Extract emb for 1462-170142-0011\n",
            "Extract emb for 1462-170142-0005\n",
            "Extract emb for 1462-170142-0007\n",
            "Extract emb for 1462-170142-0021\n",
            "Extract emb for 1462-170142-0019\n",
            "Extract emb for 1462-170142-0017\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py\", line 96, in <module>\n",
            "    for wav_info in open(wav_scp):\n",
            "                    ^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_test_enrolls_B3/wav.scp'\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py\", line 96, in <module>\n",
            "    for wav_info in open(wav_scp):\n",
            "                    ^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_test_trials_f_B3/wav.scp'\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py\", line 96, in <module>\n",
            "    for wav_info in open(wav_scp):\n",
            "                    ^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_test_trials_m_B3/wav.scp'\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py\", line 96, in <module>\n",
            "    for wav_info in open(wav_scp):\n",
            "                    ^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_dev_enrolls_B3_anon/wav.scp'\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py\", line 96, in <module>\n",
            "    for wav_info in open(wav_scp):\n",
            "                    ^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_dev_trials_f_B3_anon/wav.scp'\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py\", line 96, in <module>\n",
            "    for wav_info in open(wav_scp):\n",
            "                    ^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_dev_trials_m_B3_anon/wav.scp'\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py\", line 96, in <module>\n",
            "    for wav_info in open(wav_scp):\n",
            "                    ^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_test_enrolls_B3_anon/wav.scp'\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py\", line 96, in <module>\n",
            "    for wav_info in open(wav_scp):\n",
            "                    ^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_test_trials_f_B3_anon/wav.scp'\n",
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py\", line 96, in <module>\n",
            "    for wav_info in open(wav_scp):\n",
            "                    ^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_test_trials_m_B3_anon/wav.scp'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "\n",
        "params_file = \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_ecapa_f_ecapa_vox.yaml\"\n",
        "\n",
        "try:\n",
        "    with open(params_file) as fin:\n",
        "        params = load_hyperpyyaml(fin, {})\n",
        "    print(\"✅ YAML file loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ YAML file not found!\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Error loading YAML: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHXCSoLQtJWI",
        "outputId": "b1a5163b-644b-4aad-a076-c3ee8770c661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ YAML file loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying out A small extraction"
      ],
      "metadata": {
        "id": "6Ve5gP7n8Yuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"SPEECHBRAIN_PRETRAIN\"] = \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/pretrained_models/ECAPA-TDNN_B3/\"\n"
      ],
      "metadata": {
        "id": "otMLH_0lxPPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "wav_folder = \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_test_trials_m_B3/wav\"\n",
        "wav_scp_path = \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_test_f_trials_m_B3/wav.scp\"\n",
        "\n",
        "# Ensure the parent directory exists before writing the file\n",
        "os.makedirs(os.path.dirname(wav_scp_path), exist_ok=True)\n",
        "\n",
        "with open(wav_scp_path, \"w\") as f:\n",
        "    for file in os.listdir(wav_folder):\n",
        "        if file.endswith(\".wav\"):\n",
        "            file_path = os.path.join(wav_folder, file)\n",
        "            f.write(f\"{file.split('.')[0]} {file_path}\\n\")\n",
        "\n",
        "print(f\"✅ wav.scp created at: {wav_scp_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWrOFPs50C2o",
        "outputId": "3d685957-c56f-40dc-903e-b85db8e508a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ wav.scp created at: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_test_f_trials_m_B3/wav.scp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MwIhIKyw8xWX",
        "outputId": "d884cb3f-a929-4ace-ab0f-da1d1a213bc1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.1+cu124\n",
            "Uninstalling torch-2.5.1+cu124:\n",
            "  Successfully uninstalled torch-2.5.1+cu124\n",
            "Found existing installation: torchvision 0.20.1+cu124\n",
            "Uninstalling torchvision-0.20.1+cu124:\n",
            "  Successfully uninstalled torchvision-0.20.1+cu124\n",
            "Found existing installation: torchaudio 2.5.1+cu124\n",
            "Uninstalling torchaudio-2.5.1+cu124:\n",
            "  Successfully uninstalled torchaudio-2.5.1+cu124\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "1629fd580c0f441e9b065ad6d4b2bb4e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py \\\n",
        "/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_ecapa_f_ecapa_vox.yaml \\\n",
        "/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/data/libri_dev_enrolls_B3/wav.scp \\\n",
        "/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_dev_enrolls_B3 fbank\n"
      ],
      "metadata": {
        "id": "VO6FaGKDvnZc",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92577ac4-1a2f-417a-9a7b-004746a7a3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrain_path/embedding_model.ckpt'\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/extract_emb.py\", line 86, in <module>\n",
            "    params[\"embedding_model\"].to(params[\"device\"])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n",
            "    return self._apply(convert)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 1 more time]\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n",
            "    param_applied = fn(param)\n",
            "                    ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n",
            "    return t.to(\n",
            "           ^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 319, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaldiio\n",
        "import kaldiio\n",
        "import os\n",
        "\n",
        "# Define the directory where your files are stored\n",
        "libri_dev_enrolls_path = \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_dev_trials_m_B3\"\n",
        "\n",
        "# Find all .scp files in the directory\n",
        "scp_files = [f for f in os.listdir(libri_dev_enrolls_path) if f.endswith(\".scp\")]\n",
        "\n",
        "# Read each .scp file and load the corresponding .ark data\n",
        "enroll_data = {}\n",
        "for scp_file in scp_files:\n",
        "    scp_path = os.path.join(libri_dev_enrolls_path, scp_file)\n",
        "    data = {k: v for k, v in kaldiio.load_scp(scp_path).items()}\n",
        "    enroll_data.update(data)  # Merge all enrollments\n",
        "\n",
        "# Print loaded data information\n",
        "print(f\"Loaded {len(enroll_data)} enroll speakers from {len(scp_files)} .scp files.\")\n",
        "\n",
        "# Example: Print the first key and feature shape\n",
        "if enroll_data:\n",
        "    first_key = list(enroll_data.keys())[0]\n",
        "    print(f\"\\nFirst Enroll Key: {first_key}\")\n",
        "    print(f\"Enroll Feature Shape: {enroll_data[first_key].shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zedK7Jc2b5R",
        "outputId": "2b73195a-c550-455b-9ad3-c563c265028a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaldiio in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from kaldiio) (1.26.4)\n",
            "Loaded 0 enroll speakers from 1 .scp files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kaldi_io\n",
        "import numpy as np\n",
        "\n",
        "# Root directory containing all the folders\n",
        "root_dir = \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector\"\n",
        "skip_folder = \"libri_dev_trials_m_anon\"  # Folder to skip\n",
        "\n",
        "# # Loop through all folders in the root directory\n",
        "# for folder in os.listdir(root_dir):\n",
        "#     if folder == skip_folder:\n",
        "#         print(f\"⏩ Skipping {folder} (Already converted)\")\n",
        "#         continue  # Skip this folder\n",
        "\n",
        "#     folder_path = os.path.join(root_dir, folder)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        ark_file = os.path.join(folder_path, \"xvector.ark\")\n",
        "\n",
        "        # Ensure the .ark file exists in the folder\n",
        "        if os.path.exists(ark_file):\n",
        "            output_dir = folder_path  # Save .npy files in the same folder\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "            print(f\"🔄 Processing: {ark_file}\")\n",
        "\n",
        "            # Convert .ark to .npy\n",
        "            for key, mat in kaldi_io.read_mat_ark(ark_file):\n",
        "                np.save(os.path.join(output_dir, f\"{key}.npy\"), mat)\n",
        "\n",
        "            print(f\"✅ Conversion completed for {folder}!\")\n",
        "\n",
        "print(\"🎉 All folders processed successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISawLi_cB1f7",
        "outputId": "7634363b-f6e7-4518-f949-6b742297d93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏩ Skipping libri_dev_trials_m_anon (Already converted)\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_dev_trials_m/xvector.ark\n",
            "✅ Conversion completed for libri_dev_trials_m!\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_test_trials_m_anon/xvector.ark\n",
            "✅ Conversion completed for libri_test_trials_m_anon!\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_test_trials_m/xvector.ark\n",
            "✅ Conversion completed for libri_test_trials_m!\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_test_trials_f_anon/xvector.ark\n",
            "✅ Conversion completed for libri_test_trials_f_anon!\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_test_trials_f/xvector.ark\n",
            "✅ Conversion completed for libri_test_trials_f!\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_test_enrolls_anon/xvector.ark\n",
            "✅ Conversion completed for libri_test_enrolls_anon!\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_test_enrolls/xvector.ark\n",
            "✅ Conversion completed for libri_test_enrolls!\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_dev_trials_f_anon/xvector.ark\n",
            "✅ Conversion completed for libri_dev_trials_f_anon!\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_dev_trials_f/xvector.ark\n",
            "✅ Conversion completed for libri_dev_trials_f!\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_dev_enrolls_anon/xvector.ark\n",
            "✅ Conversion completed for libri_dev_enrolls_anon!\n",
            "🔄 Processing: /content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_dev_enrolls/xvector.ark\n",
            "✅ Conversion completed for libri_dev_enrolls!\n",
            "🎉 All folders processed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/ML_project/Pretrained_models/attacker-eval-main/output_spk_vector/libri_dev_trials_m_anon/3170-137482-0046.npy\"  # Replace with your actual file\n",
        "\n",
        "# Load the .npy file\n",
        "data = np.load(file_path)\n",
        "\n",
        "# Print basic info\n",
        "print(\"Shape:\", data.shape)\n",
        "print(\"Data Type:\", data.dtype)\n",
        "\n",
        "# Print first few values\n",
        "print(\"First few values:\\n\", data[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcLTIIDDCUbW",
        "outputId": "3b52d048-4c88-4867-8e1e-071f2ad83510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (1, 192)\n",
            "Data Type: float32\n",
            "First few values:\n",
            " [[ -2.7589903   -2.6948197    6.389781    19.179459     1.1601362\n",
            "   16.220613    -4.6195927    1.13975      9.545839    -1.5235707\n",
            "   10.879407   -14.408289    13.871846    13.43283     14.412305\n",
            "    2.9181263    7.546081    -2.882676     4.5985427    0.7223952\n",
            "   -4.2538114    8.150395    -6.3737373   -2.4482436   21.136248\n",
            "   13.501142   -10.749105    -5.5427613   -5.932976    10.449296\n",
            "   -8.191003     0.792956    -0.5181877  -10.104109    10.044406\n",
            "   -3.7288768  -25.27888    -10.977659   -11.55867     -1.8944799\n",
            "   12.333017     0.6037244   -0.6705242   -7.195377   -10.662326\n",
            "  -11.209198     7.2592807   21.263157   -11.97475     13.027384\n",
            "   -6.4728446    0.20034419  -9.524178    -9.03797      2.4972172\n",
            "    2.382045    -6.652653     0.98627424 -14.598652    -5.3627787\n",
            "   16.378748   -14.439255     6.78773      9.626267    -1.0235753\n",
            "   -9.997585   -17.239725     0.520448    -1.1402997    1.9929291\n",
            "    9.200556   -10.011002    11.522264     4.264677    -7.3942385\n",
            "    3.8044925   -3.722809     3.2680166    8.7404585   -1.609417\n",
            "    0.8933468   -7.705691    24.373043    14.465236    11.1207485\n",
            "    9.5182      -3.022455    -2.360213   -14.18079      5.5193024\n",
            "   -4.828625    -8.383278    -3.8013716   -2.1858706   -4.052811\n",
            "   -4.273988    -4.9687934   17.651283    -9.48822    -12.825893\n",
            "   12.927396     0.04434046   2.5829263    1.4054923   15.383635\n",
            "   -1.4039924   -6.958477    -9.212851     5.2489133   -1.0732533\n",
            "   20.810581    -3.2698534   11.510882    -4.6684794   22.759617\n",
            "  -10.853009    -6.1629376   10.029811    -6.9007373    8.370768\n",
            "    2.7629313  -11.123273    -0.2359949   14.275832     2.8908844\n",
            "    7.3111334   11.969135   -17.311277    -0.62803715   4.0261755\n",
            "   12.302373    -4.93646     -8.7023535   -3.3289275    6.4466853\n",
            "   -2.30259    -12.470105     7.8034067   -1.2785237    2.6003382\n",
            "    0.3654435  -10.739737   -13.2961445    1.1404053    4.0029435\n",
            "    3.4306333   -8.594245     1.064512     7.547988     0.822772\n",
            "   -9.536115    -3.239608    -7.630604    -1.9140354  -10.62478\n",
            "   -3.266296     6.9855494  -16.396229   -18.39516      0.19498123\n",
            "   -9.614773    -0.92618394  -0.23508634  10.302714    -3.872489\n",
            "   11.236707    -1.9602898    2.160868    -4.7709637    5.613058\n",
            "   -3.827044    -7.944678     4.3967457    6.632141    -1.569214\n",
            "   -5.1074376   -2.1378093    3.9645839   -3.8799808    4.263959\n",
            "   18.462618   -11.402942     4.6086006    6.6919837   -6.700037\n",
            "   -3.06953     28.91268      4.7662582   -4.793739     0.03843542\n",
            "  -12.210677   -19.608122  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FEATURE ENGINEERING (pitch)"
      ],
      "metadata": {
        "id": "lCuxF0jdpxc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install parselmouth --no-deps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyvmv7sBp1Au",
        "outputId": "e68124b9-eae5-4f8a-acab-dc8934775f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: parselmouth in /usr/local/lib/python3.11/dist-packages (1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Define paths to the folders in the shared folder\n",
        "enroll_folder = \"/content/drive/MyDrive/ML_project/libri_test_enrolls_B3/wav\"\n",
        "trial_m_folder = \"/content/drive/MyDrive/ML_project/libri_test_trials_m_B3/wav\"\n",
        "trial_f_folder = \"/content/drive/MyDrive/ML_project/libri_test_trials_f_B3/wav\"\n",
        "\n",
        "# List all .wav files in each folder\n",
        "enroll_files = [os.path.join(enroll_folder, f) for f in os.listdir(enroll_folder) if f.endswith('.wav')]\n",
        "trial_m_files = [os.path.join(trial_m_folder, f) for f in os.listdir(trial_m_folder) if f.endswith('.wav')]\n",
        "trial_f_files = [os.path.join(trial_f_folder, f) for f in os.listdir(trial_f_folder) if f.endswith('.wav')]\n",
        "\n",
        "# # Create output folders for embeddings\n",
        "os.makedirs(\"/content/drive/MyDrive/ML_project/Pitch_test_enroll_embeddings\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/ML_project/Pitch_test_trial_m_embeddings\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings\", exist_ok=True)\n",
        "\n",
        "# Function to extract pitch from a .wav file using librosa\n",
        "def extract_pitch(audio_path):\n",
        "    try:\n",
        "        # Load the audio file\n",
        "        y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "        # Extract pitch (fundamental frequency) using librosa.pyin\n",
        "        f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=librosa.note_to_hz('C1'), fmax=librosa.note_to_hz('C8'))\n",
        "\n",
        "        # Return the pitch (f0), ignoring unvoiced sections\n",
        "        pitch = f0[voiced_flag]  # Only the voiced regions\n",
        "        return pitch\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to save pitch features as .npy files\n",
        "def save_pitch_as_npy(pitch, output_path):\n",
        "    if pitch is not None:\n",
        "        np.save(output_path, pitch)\n",
        "        print(f\"Saved pitch to {output_path}\")\n",
        "    else:\n",
        "        print(f\"Failed to extract pitch for {output_path}\")\n",
        "\n",
        "# # Process and save pitch for enroll files\n",
        "for file in enroll_files:\n",
        "    pitch = extract_pitch(file)\n",
        "    if pitch is not None:\n",
        "        output_path = os.path.join(\"/content/drive/MyDrive/ML_project/Pitch_test_enroll_embeddings\", os.path.basename(file).replace('.wav', '.npy'))\n",
        "        save_pitch_as_npy(pitch, output_path)\n",
        "\n",
        "# Process and save pitch for trial_m files\n",
        "for file in trial_m_files:\n",
        "    pitch = extract_pitch(file)\n",
        "    if pitch is not None:\n",
        "        output_path = os.path.join(\"/content/drive/MyDrive/ML_project/Pitch_test_trial_m_embeddings\", os.path.basename(file).replace('.wav', '.npy'))\n",
        "        save_pitch_as_npy(pitch, output_path)\n",
        "\n",
        "# Process and save pitch for trial_f files\n",
        "for file in trial_f_files:\n",
        "    pitch = extract_pitch(file)\n",
        "    if pitch is not None:\n",
        "        output_path = os.path.join(\"/content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings\", os.path.basename(file).replace('.wav', '.npy'))\n",
        "        save_pitch_as_npy(pitch, output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJQ_YWxAw8iX",
        "outputId": "735fb936-142e-4583-901a-b6a6bd427411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-123852-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-123852-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-123852-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-123852-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-123859-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-123859-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-123859-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-123859-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-123859-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0026.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0025.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0027.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0031.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0036.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0034.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/121-127105-0035.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1221-135767-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-134647-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-134647-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-1181-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-134647-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-134647-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-134647-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-134647-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-134647-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1284-134647-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0026.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0031.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0039.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0033.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0041.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0040.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0034.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0042.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0048.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0045.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0047.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1580-141084-0049.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1836-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0025.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0026.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/1995-1837-0027.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0025.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0030.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0027.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0033.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0037.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0036.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0034.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0048.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0039.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0051.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0050.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0044.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0043.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0038.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0049.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0053.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0058.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0052.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0056.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0059.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0057.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2094-142345-0054.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134493-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0026.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0027.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0031.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0041.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0036.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0033.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0039.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0040.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/237-134500-0037.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/2961-961-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5695-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3570-5696-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0026.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0025.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0027.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0030.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0031.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0034.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0033.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0035.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0036.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0038.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0037.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0039.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0041.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0042.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0040.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0043.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0044.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0045.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0046.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0050.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0048.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0047.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0051.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0054.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0053.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0052.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0056.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3575-170457-0055.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0026.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0025.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0031.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0033.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0035.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0036.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0034.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0039.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0037.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0041.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0040.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0038.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0042.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0043.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0044.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0045.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/3729-6852-0046.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0025.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0027.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0034.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0035.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2273-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0026.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0033.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0038.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0040.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0041.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0042.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0035.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4446-2275-0043.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0025.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0026.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0030.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0031.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0033.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0034.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0035.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0039.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0041.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0040.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0038.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0037.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0036.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0043.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0045.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0046.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0042.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0050.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0054.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0053.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0051.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0047.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0048.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0052.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0049.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0057.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0059.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0056.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0055.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4507-16021-0058.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0026.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0027.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0030.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0031.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0037.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0035.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0036.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0033.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0034.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4970-29095-0038.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41797-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/4992-41806-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36586-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36586-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36586-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36377-0025.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5142-36600-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0030.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0027.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32866-0025.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/5683-32879-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0022.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0030.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0024.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0025.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0027.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0036.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0033.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0035.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/6829-68771-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294825-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0021.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0026.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0023.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0014.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0034.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0030.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0028.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0033.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0031.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0032.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0029.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0027.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0035.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0036.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0037.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8463-294828-0038.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0002.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0011.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0013.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0019.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0017.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0015.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0016.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0018.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-284449-0020.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0001.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0000.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0007.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0005.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0003.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0004.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0006.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0008.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0012.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0010.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0009.npy\n",
            "Saved pitch to /content/drive/MyDrive/ML_project/Pitch_test_trial_f_embeddings/8555-292519-0013.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CIi_v2rR7ZGd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01fa7478093a42c88871cbc0f2aa72b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c7e929de5e04185bb5d111b668fe65b",
              "IPY_MODEL_d04038695b704a3ab3189e84f096cce8",
              "IPY_MODEL_50015659624e4c4d9c8d98ae3d4f02c2"
            ],
            "layout": "IPY_MODEL_09483848d84141d486e1ea70181d4228"
          }
        },
        "083b5de742a441a9a49ddf850cbeb06f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09483848d84141d486e1ea70181d4228": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e946b6d3148470a87cafe2def2e89dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fb4208a8c084612b8f81f2a045630de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979d99fd4c9a47b79d6992e6064b758d",
            "max": 5534328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f6532a9d47145989b9b7241635f466b",
            "value": 5534328
          }
        },
        "18f8de743b3f43faac5843b7591bf1ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "245074d8d0a946e680aa8f85ad8d1273": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28930f69fd864f179706f68a3976cd8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3144ed8a0ac484fa715ecc16390c5cf",
            "placeholder": "​",
            "style": "IPY_MODEL_a584764b7262466b9eff1dfb551c000f",
            "value": "embedding_model.ckpt: 100%"
          }
        },
        "2c7e929de5e04185bb5d111b668fe65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_083b5de742a441a9a49ddf850cbeb06f",
            "placeholder": "​",
            "style": "IPY_MODEL_e09c82ffc71b45fcb830e35c725f8f2e",
            "value": "label_encoder.txt: 100%"
          }
        },
        "2d3e9bfaf611453f8208f34f79cc14f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa665cd63f464689a0ddebb0eaf84bde",
              "IPY_MODEL_0fb4208a8c084612b8f81f2a045630de",
              "IPY_MODEL_515bd341696140ee9e94dcbff887f522"
            ],
            "layout": "IPY_MODEL_fb0c37acd8c14c7fa8d6e223cfd5cbd2"
          }
        },
        "2d96f876062543798f2d6abdb079dc27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31991c1728c440a893559dd3e9387f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edfc6502b13440fbae2065f6753b2a08",
            "placeholder": "​",
            "style": "IPY_MODEL_349c3c1e02244c7a9e068e2508bae487",
            "value": "hyperparams.yaml: 100%"
          }
        },
        "349c3c1e02244c7a9e068e2508bae487": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3526b09ba70b4c22a1b3def7138e04be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f6532a9d47145989b9b7241635f466b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4419feb94bcd427b90c394c15bfe8c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d99e2b8c8a004626bb02505a0632efd8",
            "placeholder": "​",
            "style": "IPY_MODEL_ed7a43e7dd5846e4964a0e5aa477d1a6",
            "value": " 1.92k/1.92k [00:00&lt;00:00, 146kB/s]"
          }
        },
        "50015659624e4c4d9c8d98ae3d4f02c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3526b09ba70b4c22a1b3def7138e04be",
            "placeholder": "​",
            "style": "IPY_MODEL_bd29d1e9912e4eabb9129401f99c1206",
            "value": " 129k/129k [00:00&lt;00:00, 3.02MB/s]"
          }
        },
        "515bd341696140ee9e94dcbff887f522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce970b007bd246579e06ae586ec0f71c",
            "placeholder": "​",
            "style": "IPY_MODEL_e72d16ca8c344cf8b9db34338534e8e5",
            "value": " 5.53M/5.53M [00:00&lt;00:00, 144MB/s]"
          }
        },
        "531e98f676854aefb9491758e9d0597e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_245074d8d0a946e680aa8f85ad8d1273",
            "placeholder": "​",
            "style": "IPY_MODEL_c4d578aa11af437ea3267e131b657471",
            "value": " 83.3M/83.3M [00:00&lt;00:00, 195MB/s]"
          }
        },
        "5f63022e5feb4471b1960d50771b5ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f46c0262ef44adba0473dc5ecf94c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca3f81f49e0448e9b27c6d535f54525": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "866deff0bb9c4af9a60c5bc8e21f4e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed5a69752d5d40f9b53ae52952584848",
              "IPY_MODEL_eea72e95808443f3a3528b99ce3627a9",
              "IPY_MODEL_4419feb94bcd427b90c394c15bfe8c75"
            ],
            "layout": "IPY_MODEL_d4e79c19046a46878933ba21068aefad"
          }
        },
        "970c848a97794953bbc8e6ca735b0541": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "979d99fd4c9a47b79d6992e6064b758d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a584764b7262466b9eff1dfb551c000f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa665cd63f464689a0ddebb0eaf84bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d96f876062543798f2d6abdb079dc27",
            "placeholder": "​",
            "style": "IPY_MODEL_bafe0c1dd1a94f3bbe1e3f6da087b9cb",
            "value": "classifier.ckpt: 100%"
          }
        },
        "bafe0c1dd1a94f3bbe1e3f6da087b9cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd29d1e9912e4eabb9129401f99c1206": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd4b14fe103544668a43e19e6bd7b296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3569d50de084ab2af3f65ed195f8207": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4d578aa11af437ea3267e131b657471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccd026315c064d7aaba3ec1ce3e88b63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce970b007bd246579e06ae586ec0f71c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cef1d887fe1d4fe6b65b558d7407dc0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d04038695b704a3ab3189e84f096cce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f57d7e83f0b24bd5bb9cdb98b86bac81",
            "max": 128619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ca3f81f49e0448e9b27c6d535f54525",
            "value": 128619
          }
        },
        "d1e667d3954e487a8bb24a70cb13bb6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3144ed8a0ac484fa715ecc16390c5cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3cd0b86f8a945bfb43582f5789cae15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18f8de743b3f43faac5843b7591bf1ee",
            "max": 83316686,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd4b14fe103544668a43e19e6bd7b296",
            "value": 83316686
          }
        },
        "d4e79c19046a46878933ba21068aefad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5458d36d843457a85e700eaaa8f3030": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef1d887fe1d4fe6b65b558d7407dc0e",
            "placeholder": "​",
            "style": "IPY_MODEL_c3569d50de084ab2af3f65ed195f8207",
            "value": " 1.92k/1.92k [00:00&lt;00:00, 31.8kB/s]"
          }
        },
        "d99e2b8c8a004626bb02505a0632efd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ea661213434369b3813ad59967ae2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09c82ffc71b45fcb830e35c725f8f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3028a782a9d41f1aad459f0e6587958": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31991c1728c440a893559dd3e9387f43",
              "IPY_MODEL_f8823c0ee70e466eaf602cedb27d535f",
              "IPY_MODEL_d5458d36d843457a85e700eaaa8f3030"
            ],
            "layout": "IPY_MODEL_970c848a97794953bbc8e6ca735b0541"
          }
        },
        "e72d16ca8c344cf8b9db34338534e8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e734005da43a40f3b0482eaba963d330": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28930f69fd864f179706f68a3976cd8a",
              "IPY_MODEL_d3cd0b86f8a945bfb43582f5789cae15",
              "IPY_MODEL_531e98f676854aefb9491758e9d0597e"
            ],
            "layout": "IPY_MODEL_ccd026315c064d7aaba3ec1ce3e88b63"
          }
        },
        "e743b9ca126c4778a96c3aa4b41d9271": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed5a69752d5d40f9b53ae52952584848": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f63022e5feb4471b1960d50771b5ad7",
            "placeholder": "​",
            "style": "IPY_MODEL_d1e667d3954e487a8bb24a70cb13bb6d",
            "value": "mean_var_norm_emb.ckpt: 100%"
          }
        },
        "ed7a43e7dd5846e4964a0e5aa477d1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edfc6502b13440fbae2065f6753b2a08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea72e95808443f3a3528b99ce3627a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ea661213434369b3813ad59967ae2a",
            "max": 1921,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e946b6d3148470a87cafe2def2e89dc",
            "value": 1921
          }
        },
        "f57d7e83f0b24bd5bb9cdb98b86bac81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8823c0ee70e466eaf602cedb27d535f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f46c0262ef44adba0473dc5ecf94c9",
            "max": 1920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e743b9ca126c4778a96c3aa4b41d9271",
            "value": 1920
          }
        },
        "fb0c37acd8c14c7fa8d6e223cfd5cbd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}